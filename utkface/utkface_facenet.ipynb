{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40520,
     "status": "ok",
     "timestamp": 1754895834445,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "3YJUz3grE1jt",
    "outputId": "39585519-2ff6-43c1-e907-104502b29eee"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow tensorflow-addons tensorflow-hub tensorflow-datasets\n",
    "!pip install -q gdown matplotlib seaborn \n",
    "!pip install keras-facenet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, losses, metrics, Model\n",
    "from keras_facenet import FaceNet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import gdown\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1466,
     "status": "ok",
     "timestamp": 1754896145023,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "TcEuppv89pwx",
    "outputId": "2c950862-e39d-4086-b4aa-8c3d34b4f658"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "DATASET_PATH = \"C:/Users/DELL/Downloads/datasets/UTKface_inthewild/part1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41361,
     "status": "ok",
     "timestamp": 1754896195976,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "yb7BNSQsAh1j",
    "outputId": "c92cea7f-1068-488e-ffe4-c1cc8dc9e8ab"
   },
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(\"Path exists.\")\n",
    "else:\n",
    "    print(\"Path does not exist.\")\n",
    "\n",
    "# Verify dataset structure\n",
    "expected_files = [\n",
    "    \"train_labels.csv\",\n",
    "    \"val_labels.csv\",\n",
    "    \"train/\",\n",
    "    \"val/\"\n",
    "]\n",
    "\n",
    "print(f\"Loading dataset from: {DATASET_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1754896457884,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "WONN5P3SVJmf"
   },
   "outputs": [],
   "source": [
    "class UTKFaceDataProcessor:\n",
    "    def __init__(self, img_dir, img_size=160, sample_size=None, is_validation=False):\n",
    "        self.img_size = img_size\n",
    "        self.img_dir = img_dir\n",
    "        self.is_validation = is_validation\n",
    "        \n",
    "        # Parse UTKFace filenames to extract labels\n",
    "        self.parse_utkface_filenames()\n",
    "        \n",
    "        # Filter dataset to keep only valid entries\n",
    "        original_len = len(self.df)\n",
    "        # Remove entries with invalid ages (keep ages 0-116)\n",
    "        self.df = self.df[(self.df['age'] >= 0) & (self.df['age'] <= 116)].reset_index(drop=True)\n",
    "        print(f\"Removed {original_len - len(self.df)} rows with invalid ages\")\n",
    "        \n",
    "        # Sample data if specified\n",
    "        if sample_size and sample_size < len(self.df):\n",
    "            self.df = self.df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "            print(f\"Sampled {'validation' if is_validation else 'training'}: {len(self.df)} samples\")\n",
    "        \n",
    "        # Create age bins for classification (similar to FairFace)\n",
    "        self.create_age_bins()\n",
    "        \n",
    "        # Initialize label encoders\n",
    "        if not hasattr(self, 'age_encoder'):\n",
    "            self.age_encoder = LabelEncoder()\n",
    "            self.gender_encoder = LabelEncoder()\n",
    "            self.race_encoder = LabelEncoder()\n",
    "            \n",
    "            # Fit encoders\n",
    "            self.age_encoder.fit(self.df['age_bin'])\n",
    "            self.gender_encoder.fit(self.df['gender'])\n",
    "            self.race_encoder.fit(self.df['race'])\n",
    "        \n",
    "        # Encode labels\n",
    "        self.df['age_encoded'] = self.age_encoder.transform(self.df['age_bin'])\n",
    "        self.df['gender_encoded'] = self.gender_encoder.transform(self.df['gender'])\n",
    "        self.df['race_encoded'] = self.race_encoder.transform(self.df['race'])\n",
    "        \n",
    "        self.num_classes = {\n",
    "            'age': len(self.age_encoder.classes_),\n",
    "            'gender': len(self.gender_encoder.classes_),\n",
    "            'race': len(self.race_encoder.classes_)\n",
    "        }\n",
    "        \n",
    "        print(f\"Classes - Age: {self.num_classes['age']}, Gender: {self.num_classes['gender']}, Race: {self.num_classes['race']}\")\n",
    "        if not is_validation:\n",
    "            print(f\"Age range: {min(self.df['age'])}-{max(self.df['age'])}\")\n",
    "            print(f\"Age bins: {list(self.age_encoder.classes_)}\")\n",
    "            print(f\"Gender groups: {list(self.gender_encoder.classes_)}\")\n",
    "            print(f\"Race groups: {list(self.race_encoder.classes_)}\")\n",
    "    \n",
    "    def create_age_bins(self):\n",
    "        \"\"\"Create age bins similar to FairFace format\"\"\"\n",
    "        def age_to_bin(age):\n",
    "            if age <= 2:\n",
    "                return '0-2'\n",
    "            elif age <= 9:\n",
    "                return '3-9'\n",
    "            elif age <= 19:\n",
    "                return '10-19'\n",
    "            elif age <= 29:\n",
    "                return '20-29'\n",
    "            elif age <= 39:\n",
    "                return '30-39'\n",
    "            elif age <= 49:\n",
    "                return '40-49'\n",
    "            elif age <= 59:\n",
    "                return '50-59'\n",
    "            elif age <= 69:\n",
    "                return '60-69'\n",
    "            else:\n",
    "                return '70+'\n",
    "        \n",
    "        self.df['age_bin'] = self.df['age'].apply(age_to_bin)\n",
    "        print(f\"Age bin distribution:\\n{self.df['age_bin'].value_counts().sort_index()}\")\n",
    "    \n",
    "    def parse_utkface_filenames(self):\n",
    "        \"\"\"Parse UTKFace filenames to extract age, gender, race labels\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        for filename in os.listdir(self.img_dir):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                parts = filename.split('_')\n",
    "                if len(parts) >= 3:\n",
    "                    try:\n",
    "                        age = int(parts[0])\n",
    "                        gender_code = parts[1]  # 0: female, 1: male\n",
    "                        race_code = parts[2]    # 0: White, 1: Black, 2: Asian, 3: Indian, 4: Others\n",
    "                        \n",
    "                        # Map gender codes to labels\n",
    "                        gender_mapping = {'0': 'Female', '1': 'Male'}\n",
    "                        gender_label = gender_mapping.get(gender_code, 'Unknown')\n",
    "                        \n",
    "                        # Map race codes to labels\n",
    "                        race_mapping = {\n",
    "                            '0': 'White', \n",
    "                            '1': 'Black', \n",
    "                            '2': 'East Asian', \n",
    "                            '3': 'Indian', \n",
    "                            '4': 'Others'\n",
    "                        }\n",
    "                        race_label = race_mapping.get(race_code, 'Unknown')\n",
    "                        \n",
    "                        # Skip unknown labels\n",
    "                        if gender_label != 'Unknown' and race_label != 'Unknown':\n",
    "                            data.append({\n",
    "                                'file': filename,\n",
    "                                'age': age,\n",
    "                                'gender': gender_label,\n",
    "                                'race': race_label\n",
    "                            })\n",
    "                    except (ValueError, IndexError):\n",
    "                        print(f\"Skipping invalid filename: {filename}\")\n",
    "                        continue\n",
    "        \n",
    "        self.df = pd.DataFrame(data)\n",
    "        print(f\"Loaded {len(self.df)} valid images from UTKFace dataset\")\n",
    "        \n",
    "        # Print dataset statistics\n",
    "        print(f\"\\nDataset Statistics:\")\n",
    "        print(f\"Age distribution: min={self.df['age'].min()}, max={self.df['age'].max()}, mean={self.df['age'].mean():.1f}\")\n",
    "        print(f\"Gender distribution:\\n{self.df['gender'].value_counts()}\")\n",
    "        print(f\"Race distribution:\\n{self.df['race'].value_counts()}\")\n",
    "    \n",
    "    def filter_missing_files(self):\n",
    "        \"\"\"Filter out rows where image files don't exist\"\"\"\n",
    "        print(f\"Original dataset size: {len(self.df)}\")\n",
    "        \n",
    "        existing_files = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_path = os.path.join(self.img_dir, row['file'])\n",
    "            if os.path.exists(img_path):\n",
    "                existing_files.append(idx)\n",
    "        \n",
    "        self.df = self.df.loc[existing_files].reset_index(drop=True)\n",
    "        print(f\"Filtered dataset size: {len(self.df)}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def load_and_preprocess_image(self, image_path, augment=False):\n",
    "        \"\"\"Load and preprocess single image\"\"\"\n",
    "        try:\n",
    "            if not tf.io.gfile.exists(image_path):\n",
    "                print(f\"Warning: File not found: {image_path}\")\n",
    "                return tf.zeros([self.img_size, self.img_size, 3], dtype=tf.float32)\n",
    "            \n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_image(image, channels=3)\n",
    "            image = tf.image.resize(image, [self.img_size, self.img_size])\n",
    "            image = tf.cast(image, tf.float32) / 255.0\n",
    "            \n",
    "            if augment:\n",
    "                image = tf.image.random_flip_left_right(image)\n",
    "                image = tf.image.random_brightness(image, 0.1)\n",
    "                image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "                image = tf.image.random_saturation(image, 0.9, 1.1)\n",
    "                image = tf.image.random_hue(image, 0.05)\n",
    "            \n",
    "            image = tf.image.per_image_standardization(image)\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            return tf.zeros([self.img_size, self.img_size, 3], dtype=tf.float32)\n",
    "    \n",
    "    def create_dataset(self, batch_size=32, augment=False, shuffle=True):\n",
    "        \"\"\"Create TensorFlow dataset\"\"\"\n",
    "        def generator():\n",
    "            indices = np.arange(len(self.df))\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "            \n",
    "            for idx in indices:\n",
    "                row = self.df.iloc[idx]\n",
    "                img_path = os.path.join(self.img_dir, row['file'])\n",
    "                \n",
    "                image = self.load_and_preprocess_image(img_path, augment)\n",
    "                \n",
    "                yield (\n",
    "                    image,\n",
    "                    {\n",
    "                        'age_output': tf.cast(row['age_encoded'], dtype=tf.int32),\n",
    "                        'gender_output': tf.cast(row['gender_encoded'], dtype=tf.int32),\n",
    "                        'race_output': tf.cast(row['race_encoded'], dtype=tf.int32)\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(self.img_size, self.img_size, 3), dtype=tf.float32),\n",
    "                {\n",
    "                    'age_output': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "                    'gender_output': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "                    'race_output': tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=1000)\n",
    "        \n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1754896206318,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "1drJhus-PYHr"
   },
   "outputs": [],
   "source": [
    "class FaceNetMultiTask(tf.keras.Model):\n",
    "    def __init__(self, num_age_classes, num_gender_classes, num_race_classes,\n",
    "                 freeze_backbone=False):\n",
    "        super(FaceNetMultiTask, self).__init__()\n",
    "\n",
    "        self.backbone = FaceNet().model\n",
    "\n",
    "        # Freeze backbone\n",
    "        if freeze_backbone:\n",
    "            self.backbone.trainable = False\n",
    "\n",
    "        # Shared dense layer\n",
    "        self.shared_dense = layers.Dense(512, activation='relu', name='shared_dense')\n",
    "        self.shared_dropout = layers.Dropout(0.7, name='shared_dropout')\n",
    "\n",
    "        # Task-specific classification heads\n",
    "        # age branch\n",
    "        self.age_classifier = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', name='age_dense'),\n",
    "            layers.Dense(num_age_classes, activation='softmax', name='age_output')\n",
    "        ], name='age_head')\n",
    "\n",
    "        # gender branch\n",
    "        self.gender_classifier = tf.keras.Sequential([\n",
    "            layers.Dense(num_gender_classes, activation='softmax', name='gender_output')\n",
    "        ], name='gender_head')\n",
    "\n",
    "        # race branch\n",
    "        self.race_classifier = tf.keras.Sequential([\n",
    "            layers.Dense(num_race_classes, activation='softmax', name='race_output')\n",
    "        ], name='race_head')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Get FaceNet embeddings\n",
    "        embeddings = self.backbone(inputs, training=training)\n",
    "\n",
    "        # Shared processing\n",
    "        shared_features = self.shared_dense(embeddings, training=training)\n",
    "        shared_features = self.shared_dropout(shared_features, training=training)\n",
    "\n",
    "        # Task-specific predictions\n",
    "        age_pred = self.age_classifier(shared_features, training=training)\n",
    "        gender_pred = self.gender_classifier(shared_features, training=training)\n",
    "        race_pred = self.race_classifier(shared_features, training=training)\n",
    "\n",
    "        return {\n",
    "            'age_output': age_pred,\n",
    "            'gender_output': gender_pred,\n",
    "            'race_output': race_pred\n",
    "        }\n",
    "\n",
    "def create_and_compile_model(num_age_classes, num_gender_classes, num_race_classes, freeze_backbone=False):\n",
    "    \"\"\"Create and compile the multi-task model\"\"\"\n",
    "\n",
    "    model = FaceNetMultiTask(\n",
    "        num_age_classes=num_age_classes,\n",
    "        num_gender_classes=num_gender_classes,\n",
    "        num_race_classes=num_race_classes,\n",
    "        freeze_backbone=freeze_backbone\n",
    "    )\n",
    "\n",
    "    # Build the model\n",
    "    model.build((None, 160, 160, 3))\n",
    "\n",
    "    # Optimizer with learning rate schedule\n",
    "    initial_lr = 0.001\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr),\n",
    "        loss={\n",
    "            'age_output': losses.SparseCategoricalCrossentropy(),\n",
    "            'gender_output': losses.SparseCategoricalCrossentropy(),\n",
    "            'race_output': losses.SparseCategoricalCrossentropy()\n",
    "        },\n",
    "        loss_weights={\n",
    "            'age_output': 1.0,\n",
    "            'gender_output': 1.0,\n",
    "            'race_output': 1.0\n",
    "        },\n",
    "        metrics={\n",
    "            'age_output': ['sparse_categorical_accuracy'],\n",
    "            'gender_output': ['sparse_categorical_accuracy'],\n",
    "            'race_output': ['sparse_categorical_accuracy']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"\\nModel compiled successfully!\")\n",
    "    print(f\"   - Backbone frozen: {freeze_backbone}\")\n",
    "    print(f\"   - Learning rate: {initial_lr}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341269,
     "status": "ok",
     "timestamp": 1754896803647,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "2WTcl-yIykK6",
    "outputId": "fedae64e-41f0-4534-d8c6-547b5ebb1ed3"
   },
   "outputs": [],
   "source": [
    "    BATCH_SIZE = 32\n",
    "    IMG_SIZE = 160\n",
    "    EPOCHS = 50\n",
    "    SAMPLE_SIZE = None \n",
    "    \n",
    "    print(\"Creating training data processor...\")\n",
    "    # Split the dataset manually since UTKFace doesn't come pre-split\n",
    "    all_files = [f for f in os.listdir(DATASET_PATH) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    train_files = all_files[:int(0.8 * len(all_files))]\n",
    "    val_files = all_files[int(0.8 * len(all_files)):]\n",
    "    \n",
    "    # Create temporary directories for train/val split\n",
    "    import shutil\n",
    "    train_dir = os.path.join(DATASET_PATH, 'train_temp')\n",
    "    val_dir = os.path.join(DATASET_PATH, 'val_temp')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy files to train/val directories (or create symlinks)\n",
    "    for f in train_files:\n",
    "        src = os.path.join(DATASET_PATH, f)\n",
    "        dst = os.path.join(train_dir, f)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy2(src, dst)\n",
    "    \n",
    "    for f in val_files:\n",
    "        src = os.path.join(DATASET_PATH, f)\n",
    "        dst = os.path.join(val_dir, f)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy2(src, dst)\n",
    "    \n",
    "    train_processor = UTKFaceDataProcessor(\n",
    "        train_dir,\n",
    "        img_size=IMG_SIZE,\n",
    "        sample_size=SAMPLE_SIZE,\n",
    "        is_validation=False\n",
    "    ).filter_missing_files()\n",
    "    \n",
    "    print(\"\\nCreating validation data processor...\")\n",
    "    val_processor = UTKFaceDataProcessor(\n",
    "        val_dir,\n",
    "        img_size=IMG_SIZE,\n",
    "        sample_size=SAMPLE_SIZE//5 if SAMPLE_SIZE else None,\n",
    "        is_validation=True\n",
    "    ).filter_missing_files()\n",
    "    \n",
    "    # Copy encoders from training to validation processor\n",
    "    val_processor.age_encoder = train_processor.age_encoder\n",
    "    val_processor.gender_encoder = train_processor.gender_encoder\n",
    "    val_processor.race_encoder = train_processor.race_encoder\n",
    "    val_processor.num_classes = train_processor.num_classes\n",
    "    \n",
    "    # Re-encode validation labels with training encoders\n",
    "    val_processor.df['age_encoded'] = val_processor.age_encoder.transform(val_processor.df['age_bin'])\n",
    "    val_processor.df['gender_encoded'] = val_processor.gender_encoder.transform(val_processor.df['gender'])\n",
    "    val_processor.df['race_encoded'] = val_processor.race_encoder.transform(val_processor.df['race'])\n",
    "    \n",
    "    print(\"\\nCreating datasets...\")\n",
    "    train_dataset = train_processor.create_dataset(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        augment=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = val_processor.create_dataset(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        augment=False,\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 7582,
     "status": "ok",
     "timestamp": 1754896811234,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "bv7OlybkARBz",
    "outputId": "7bb5ce51-779d-49f7-cde1-dd7c832d04b9"
   },
   "outputs": [],
   "source": [
    "print(\"Building model...\")\n",
    "model = create_and_compile_model(\n",
    "    num_age_classes=train_processor.num_classes['age'],\n",
    "    num_gender_classes=train_processor.num_classes['gender'],\n",
    "    num_race_classes=train_processor.num_classes['race'],\n",
    "    freeze_backbone=True \n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1754897108153,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "MWotdjMtbOOw"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_utkface_facenet_model.h5',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.CSVLogger('utkface_training_log.csv')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "19fY68tkbhW6"
   },
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 172946,
     "status": "aborted",
     "timestamp": 1754895966752,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "BEU-ZGsXWRoh"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwNWKg_bW2Gg"
   },
   "outputs": [],
   "source": [
    "print(\"Available history keys:\", list(history.history.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfeTgSyaEQxk"
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history for all tasks\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # Loss plots\n",
    "    axes[0, 0].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[0, 0].set_title('Total Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Age accuracy\n",
    "    axes[0, 1].plot(history.history['age_output_sparse_categorical_accuracy'], label='Train Acc')\n",
    "    axes[0, 1].plot(history.history['val_age_output_sparse_categorical_accuracy'], label='Val Acc')\n",
    "    axes[0, 1].set_title('Age Classification Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Gender accuracy\n",
    "    axes[0, 2].plot(history.history['gender_output_sparse_categorical_accuracy'], label='Train Acc')\n",
    "    axes[0, 2].plot(history.history['val_gender_output_sparse_categorical_accuracy'], label='Val Acc')\n",
    "    axes[0, 2].set_title('Gender Classification Accuracy')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Accuracy')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True)\n",
    "    \n",
    "    # Race accuracy\n",
    "    axes[1, 0].plot(history.history['race_output_sparse_categorical_accuracy'], label='Train Acc')\n",
    "    axes[1, 0].plot(history.history['val_race_output_sparse_categorical_accuracy'], label='Val Acc')\n",
    "    axes[1, 0].set_title('Race Classification Accuracy')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Individual loss plots\n",
    "    axes[1, 1].plot(history.history['age_output_loss'], label='Age Loss')\n",
    "    axes[1, 1].plot(history.history['gender_output_loss'], label='Gender Loss')\n",
    "    axes[1, 1].plot(history.history['race_output_loss'], label='Race Loss')\n",
    "    axes[1, 1].set_title('Task-specific Losses (Train)')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    # Learning rate\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 2].plot(history.history['lr'])\n",
    "        axes[1, 2].set_title('Learning Rate')\n",
    "        axes[1, 2].set_xlabel('Epoch')\n",
    "        axes[1, 2].set_ylabel('LR')\n",
    "        axes[1, 2].set_yscale('log')\n",
    "        axes[1, 2].grid(True)\n",
    "    else:\n",
    "        axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5bCJhEpWFdK"
   },
   "outputs": [],
   "source": [
    "def predict_sample_utkface(model, img_path, train_processor, img_size=(160, 160)):\n",
    "    \"\"\"\n",
    "    Predict demographics for a single image using UTKFace model\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, img_size)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(img, verbose=0)\n",
    "\n",
    "    # Extract predictions\n",
    "    age_pred = np.argmax(preds['age_output'][0])\n",
    "    gender_pred = np.argmax(preds['gender_output'][0])\n",
    "    race_pred = np.argmax(preds['race_output'][0])\n",
    "\n",
    "    # Decode labels\n",
    "    age_label = train_processor.age_encoder.inverse_transform([age_pred])[0]\n",
    "    gender_label = train_processor.gender_encoder.inverse_transform([gender_pred])[0]\n",
    "    race_label = train_processor.race_encoder.inverse_transform([race_pred])[0]\n",
    "\n",
    "    # Display\n",
    "    display_img = tf.io.read_file(img_path)\n",
    "    display_img = tf.image.decode_image(display_img, channels=3)\n",
    "    display_img = tf.image.resize(display_img, img_size)\n",
    "    display_img = tf.cast(display_img, tf.float32) / 255.0\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(display_img)\n",
    "    plt.title(f\"Predictions:\\nAge: {age_label}\\nGender: {gender_label}\\nRace: {race_label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return age_label, gender_label, race_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_dataset, val_processor):\n",
    "    \"\"\"Evaluate model performance and create confusion matrices\"\"\"\n",
    "    print(\"Evaluating model...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_true_age = []\n",
    "    y_true_gender = []\n",
    "    y_true_race = []\n",
    "    y_pred_age = []\n",
    "    y_pred_gender = []\n",
    "    y_pred_race = []\n",
    "    \n",
    "    for batch_x, batch_y in val_dataset:\n",
    "        preds = model.predict(batch_x, verbose=0)\n",
    "        \n",
    "        y_true_age.extend(batch_y['age_output'].numpy())\n",
    "        y_true_gender.extend(batch_y['gender_output'].numpy())\n",
    "        y_true_race.extend(batch_y['race_output'].numpy())\n",
    "        \n",
    "        y_pred_age.extend(np.argmax(preds['age_output'], axis=1))\n",
    "        y_pred_gender.extend(np.argmax(preds['gender_output'], axis=1))\n",
    "        y_pred_race.extend(np.argmax(preds['race_output'], axis=1))\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    \n",
    "    age_acc = accuracy_score(y_true_age, y_pred_age)\n",
    "    gender_acc = accuracy_score(y_true_gender, y_pred_gender)\n",
    "    race_acc = accuracy_score(y_true_race, y_pred_race)\n",
    "    \n",
    "    print(f\"\\nValidation Accuracies:\")\n",
    "    print(f\"Age: {age_acc:.4f}\")\n",
    "    print(f\"Gender: {gender_acc:.4f}\")\n",
    "    print(f\"Race: {race_acc:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrices\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Age confusion matrix\n",
    "    age_cm = confusion_matrix(y_true_age, y_pred_age)\n",
    "    sns.heatmap(age_cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "                xticklabels=val_processor.age_encoder.classes_,\n",
    "                yticklabels=val_processor.age_encoder.classes_)\n",
    "    axes[0].set_title(f'Age Confusion Matrix (Acc: {age_acc:.3f})')\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('True')\n",
    "    \n",
    "    # Gender confusion matrix\n",
    "    gender_cm = confusion_matrix(y_true_gender, y_pred_gender)\n",
    "    sns.heatmap(gender_cm, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n",
    "                xticklabels=val_processor.gender_encoder.classes_,\n",
    "                yticklabels=val_processor.gender_encoder.classes_)\n",
    "    axes[1].set_title(f'Gender Confusion Matrix (Acc: {gender_acc:.3f})')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('True')\n",
    "    \n",
    "    # Race confusion matrix\n",
    "    race_cm = confusion_matrix(y_true_race, y_pred_race)\n",
    "    sns.heatmap(race_cm, annot=True, fmt='d', cmap='Blues', ax=axes[2],\n",
    "                xticklabels=val_processor.race_encoder.classes_,\n",
    "                yticklabels=val_processor.race_encoder.classes_)\n",
    "    axes[2].set_title(f'Race Confusion Matrix (Acc: {race_acc:.3f})')\n",
    "    axes[2].set_xlabel('Predicted')\n",
    "    axes[2].set_ylabel('True')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Detailed classification reports\n",
    "    print(\"\\nDetailed Classification Reports:\")\n",
    "    print(\"\\n=== AGE CLASSIFICATION ===\")\n",
    "    print(classification_report(y_true_age, y_pred_age, \n",
    "                              target_names=val_processor.age_encoder.classes_))\n",
    "    \n",
    "    print(\"\\n=== GENDER CLASSIFICATION ===\")\n",
    "    print(classification_report(y_true_gender, y_pred_gender, \n",
    "                              target_names=val_processor.gender_encoder.classes_))\n",
    "    \n",
    "    print(\"\\n=== RACE CLASSIFICATION ===\")\n",
    "    print(classification_report(y_true_race, y_pred_race, \n",
    "                              target_names=val_processor.race_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_processors(model, train_processor, model_name=\"utkface_facenet_model\"):\n",
    "    \"\"\"Save trained model and label encoders\"\"\"\n",
    "    # Save the complete model\n",
    "    model.save(f\"{model_name}.h5\")\n",
    "    print(f\"Model saved as {model_name}.h5\")\n",
    "    \n",
    "    # Save label encoders\n",
    "    import pickle\n",
    "    encoders = {\n",
    "        'age_encoder': train_processor.age_encoder,\n",
    "        'gender_encoder': train_processor.gender_encoder,\n",
    "        'race_encoder': train_processor.race_encoder,\n",
    "        'num_classes': train_processor.num_classes\n",
    "    }\n",
    "    \n",
    "    with open(f\"{model_name}_encoders.pkl\", 'wb') as f:\n",
    "        pickle.dump(encoders, f)\n",
    "    print(f\"Encoders saved as {model_name}_encoders.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_processors(model_path, encoders_path):\n",
    "    \"\"\"Load trained model and label encoders\"\"\"\n",
    "    # Load model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    \n",
    "    # Load encoders\n",
    "    import pickle\n",
    "    with open(encoders_path, 'rb') as f:\n",
    "        encoders = pickle.load(f)\n",
    "    \n",
    "    print(\"Encoders loaded successfully\")\n",
    "    return model, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import lime\n",
    "from lime import lime_image\n",
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, layer_name=None):\n",
    "        self.model = model\n",
    "        self.layer_name = layer_name or self.find_target_layer()\n",
    "    \n",
    "    def find_target_layer(self):\n",
    "        \"\"\"Find the last convolutional layer in the backbone\"\"\"\n",
    "        for layer in reversed(self.model.backbone.layers):\n",
    "            if len(layer.output_shape) == 4:  # Conv layer has 4D output\n",
    "                return layer.name\n",
    "        return None\n",
    "    \n",
    "    def generate_gradcam(self, image, task='age', class_idx=None):\n",
    "        \"\"\"Generate Grad-CAM heatmap\"\"\"\n",
    "        if self.layer_name is None:\n",
    "            print(\"No suitable convolutional layer found\")\n",
    "            return None, None\n",
    "        \n",
    "        # Create a model that outputs both the target layer and final predictions\n",
    "        grad_model = tf.keras.Model(\n",
    "            inputs=self.model.inputs,\n",
    "            outputs=[self.model.get_layer(self.layer_name).output, self.model.output]\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            conv_outputs, predictions = grad_model(image)\n",
    "            \n",
    "            # Get the prediction for the specified task\n",
    "            if task == 'age':\n",
    "                pred_output = predictions['age_output']\n",
    "            elif task == 'gender':\n",
    "                pred_output = predictions['gender_output']\n",
    "            elif task == 'race':\n",
    "                pred_output = predictions['race_output']\n",
    "            else:\n",
    "                raise ValueError(\"Task must be 'age', 'gender', or 'race'\")\n",
    "            \n",
    "            if class_idx is None:\n",
    "                class_idx = tf.argmax(pred_output[0])\n",
    "            \n",
    "            loss = pred_output[:, class_idx]\n",
    "        \n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss, conv_outputs)\n",
    "        \n",
    "        # Global average pooling of gradients\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "        \n",
    "        # Multiply feature maps by their gradients\n",
    "        conv_outputs = conv_outputs[0]\n",
    "        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "        \n",
    "        # Normalize heatmap\n",
    "        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "        heatmap = heatmap.numpy()\n",
    "        \n",
    "        return heatmap, predictions\n",
    "\n",
    "def visualize_gradcam(image_path, model, train_processor, tasks=['age', 'gender', 'race']):\n",
    "    \"\"\"Visualize Grad-CAM for multiple tasks\"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    original_img = tf.image.resize(img, [160, 160])\n",
    "    \n",
    "    # Preprocess for model\n",
    "    processed_img = tf.cast(original_img, tf.float32) / 255.0\n",
    "    processed_img = tf.image.per_image_standardization(processed_img)\n",
    "    processed_img = tf.expand_dims(processed_img, axis=0)\n",
    "    \n",
    "    # Initialize Grad-CAM\n",
    "    gradcam = GradCAM(model)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, len(tasks), figsize=(5*len(tasks), 10))\n",
    "    if len(tasks) == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i, task in enumerate(tasks):\n",
    "        # Generate Grad-CAM\n",
    "        heatmap, predictions = gradcam.generate_gradcam(processed_img, task=task)\n",
    "        \n",
    "        if heatmap is not None:\n",
    "            # Get prediction\n",
    "            if task == 'age':\n",
    "                pred_idx = np.argmax(predictions['age_output'][0])\n",
    "                pred_label = train_processor.age_encoder.inverse_transform([pred_idx])[0]\n",
    "            elif task == 'gender':\n",
    "                pred_idx = np.argmax(predictions['gender_output'][0])\n",
    "                pred_label = train_processor.gender_encoder.inverse_transform([pred_idx])[0]\n",
    "            elif task == 'race':\n",
    "                pred_idx = np.argmax(predictions['race_output'][0])\n",
    "                pred_label = train_processor.race_encoder.inverse_transform([pred_idx])[0]\n",
    "            \n",
    "            # Display original image\n",
    "            axes[0, i].imshow(original_img.numpy().astype('uint8'))\n",
    "            axes[0, i].set_title(f'{task.title()}: {pred_label}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Resize heatmap to match image size\n",
    "            heatmap_resized = cv2.resize(heatmap, (160, 160))\n",
    "            \n",
    "            # Create overlay\n",
    "            heatmap_colored = cm.jet(heatmap_resized)[:, :, :3]\n",
    "            overlay = original_img.numpy().astype('float32') / 255.0\n",
    "            overlay = 0.6 * overlay + 0.4 * heatmap_colored\n",
    "            \n",
    "            axes[1, i].imshow(overlay)\n",
    "            axes[1, i].set_title(f'Grad-CAM: {task.title()}')\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_lime(model, image_path, train_processor, task='age', num_samples=1000):\n",
    "    \"\"\"Generate LIME explanation for a specific task\"\"\"\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, [160, 160])\n",
    "    img_array = img.numpy().astype('uint8')\n",
    "    \n",
    "    # Define prediction function for LIME\n",
    "    def predict_fn(images):\n",
    "        batch = []\n",
    "        for img in images:\n",
    "            # Preprocess each image\n",
    "            processed = tf.cast(img, tf.float32) / 255.0\n",
    "            processed = tf.image.per_image_standardization(processed)\n",
    "            batch.append(processed)\n",
    "        \n",
    "        batch = tf.stack(batch)\n",
    "        predictions = model.predict(batch, verbose=0)\n",
    "        \n",
    "        # Return predictions for the specified task\n",
    "        if task == 'age':\n",
    "            return predictions['age_output']\n",
    "        elif task == 'gender':\n",
    "            return predictions['gender_output']\n",
    "        elif task == 'race':\n",
    "            return predictions['race_output']\n",
    "    \n",
    "    # Initialize LIME explainer\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    \n",
    "    # Generate explanation\n",
    "    explanation = explainer.explain_instance(\n",
    "        img_array,\n",
    "        predict_fn,\n",
    "        top_labels=5,\n",
    "        hide_color=0,\n",
    "        num_samples=num_samples\n",
    "    )\n",
    "    \n",
    "    # Get prediction\n",
    "    processed_img = tf.cast(img, tf.float32) / 255.0\n",
    "    processed_img = tf.image.per_image_standardization(processed_img)\n",
    "    processed_img = tf.expand_dims(processed_img, axis=0)\n",
    "    predictions = model.predict(processed_img, verbose=0)\n",
    "    \n",
    "    if task == 'age':\n",
    "        pred_idx = np.argmax(predictions['age_output'][0])\n",
    "        pred_label = train_processor.age_encoder.inverse_transform([pred_idx])[0]\n",
    "        task_pred = predictions['age_output'][0]\n",
    "    elif task == 'gender':\n",
    "        pred_idx = np.argmax(predictions['gender_output'][0])\n",
    "        pred_label = train_processor.gender_encoder.inverse_transform([pred_idx])[0]\n",
    "        task_pred = predictions['gender_output'][0]\n",
    "    elif task == 'race':\n",
    "        pred_idx = np.argmax(predictions['race_output'][0])\n",
    "        pred_label = train_processor.race_encoder.inverse_transform([pred_idx])[0]\n",
    "        task_pred = predictions['race_output'][0]\n",
    "    \n",
    "    # Visualize explanation\n",
    "    temp, mask = explanation.get_image_and_mask(\n",
    "        pred_idx, \n",
    "        positive_only=True, \n",
    "        num_features=10, \n",
    "        hide_rest=False\n",
    "    )\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img_array)\n",
    "    axes[0].set_title(f'Original Image\\n{task.title()}: {pred_label}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # LIME explanation\n",
    "    axes[1].imshow(temp)\n",
    "    axes[1].set_title(f'LIME Explanation\\nTop features for {pred_label}')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Prediction probabilities\n",
    "    if task == 'age':\n",
    "        labels = train_processor.age_encoder.classes_\n",
    "    elif task == 'gender':\n",
    "        labels = train_processor.gender_encoder.classes_\n",
    "    elif task == 'race':\n",
    "        labels = train_processor.race_encoder.classes_\n",
    "    \n",
    "    # Show top 5 predictions\n",
    "    top_indices = np.argsort(task_pred)[-5:][::-1]\n",
    "    top_probs = task_pred[top_indices]\n",
    "    top_labels = [labels[i] for i in top_indices]\n",
    "    \n",
    "    axes[2].barh(range(len(top_labels)), top_probs)\n",
    "    axes[2].set_yticks(range(len(top_labels)))\n",
    "    axes[2].set_yticklabels(top_labels)\n",
    "    axes[2].set_xlabel('Probability')\n",
    "    axes[2].set_title(f'Top {len(top_labels)} Predictions')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_shap(model, image_path, train_processor, task='age', num_samples=100):\n",
    "    \"\"\"Generate SHAP explanation for a specific task\"\"\"\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, [160, 160])\n",
    "    img_processed = tf.cast(img, tf.float32) / 255.0\n",
    "    img_processed = tf.image.per_image_standardization(img_processed)\n",
    "    img_processed = tf.expand_dims(img_processed, axis=0)\n",
    "    \n",
    "    # Create a wrapper function for the specific task\n",
    "    def model_predict(x):\n",
    "        predictions = model.predict(x, verbose=0)\n",
    "        if task == 'age':\n",
    "            return predictions['age_output']\n",
    "        elif task == 'gender':\n",
    "            return predictions['gender_output']\n",
    "        elif task == 'race':\n",
    "            return predictions['race_output']\n",
    "    \n",
    "    # Create background dataset (sample from validation set)\n",
    "    background_images = []\n",
    "    count = 0\n",
    "    for batch_x, _ in val_dataset:\n",
    "        if count >= num_samples:\n",
    "            break\n",
    "        for img in batch_x:\n",
    "            if count >= num_samples:\n",
    "                break\n",
    "            background_images.append(img.numpy())\n",
    "            count += 1\n",
    "    \n",
    "    background = np.array(background_images[:min(50, len(background_images))])  # Use smaller background for speed\n",
    "    \n",
    "    # Initialize SHAP explainer\n",
    "    explainer = shap.DeepExplainer(model_predict, background)\n",
    "    \n",
    "    # Generate SHAP values\n",
    "    shap_values = explainer.shap_values(img_processed)\n",
    "    \n",
    "    # Get prediction\n",
    "    predictions = model.predict(img_processed, verbose=0)\n",
    "    if task == 'age':\n",
    "        pred_idx = np.argmax(predictions['age_output'][0])\n",
    "        pred_label = train_processor.age_encoder.inverse_transform([pred_idx])[0]\n",
    "        labels = train_processor.age_encoder.classes_\n",
    "    elif task == 'gender':\n",
    "        pred_idx = np.argmax(predictions['gender_output'][0])\n",
    "        pred_label = train_processor.gender_encoder.inverse_transform([pred_idx])[0]\n",
    "        labels = train_processor.gender_encoder.classes_\n",
    "    elif task == 'race':\n",
    "        pred_idx = np.argmax(predictions['race_output'][0])\n",
    "        pred_label = train_processor.race_encoder.inverse_transform([pred_idx])[0]\n",
    "        labels = train_processor.race_encoder.classes_\n",
    "    \n",
    "    # Visualize SHAP values\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    original_display = img.numpy().astype('uint8')\n",
    "    axes[0].imshow(original_display)\n",
    "    axes[0].set_title(f'Original Image\\n{task.title()}: {pred_label}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # SHAP explanation for predicted class\n",
    "    shap_img = shap_values[pred_idx][0]\n",
    "    \n",
    "    # Normalize SHAP values for visualization\n",
    "    shap_img_norm = np.abs(shap_img)\n",
    "    shap_img_norm = (shap_img_norm - shap_img_norm.min()) / (shap_img_norm.max() - shap_img_norm.min())\n",
    "    \n",
    "    axes[1].imshow(shap_img_norm, cmap='hot')\n",
    "    axes[1].set_title(f'SHAP Explanation\\nFor {pred_label}')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay SHAP on original image\n",
    "    overlay = original_display.astype('float32') / 255.0\n",
    "    heatmap = cv2.resize(shap_img_norm, (160, 160))\n",
    "    heatmap_colored = cm.hot(heatmap)[:, :, :3]\n",
    "    overlay = 0.7 * overlay + 0.3 * heatmap_colored\n",
    "    \n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(f'SHAP Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction_comprehensive(model, data_processor, image_path, task='age'):\n",
    "    \"\"\"\n",
    "    Generate comprehensive explanations using LIME, SHAP, and Grad-CAM\n",
    "    \"\"\"\n",
    "    print(f\"Generating comprehensive explanations for {task} prediction...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load image for display\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, [160, 160])\n",
    "    \n",
    "    # Get model prediction\n",
    "    processed_img = tf.cast(img, tf.float32) / 255.0\n",
    "    processed_img = tf.image.per_image_standardization(processed_img)\n",
    "    processed_img = tf.expand_dims(processed_img, axis=0)\n",
    "    \n",
    "    predictions = model.predict(processed_img, verbose=0)\n",
    "    \n",
    "    # Decode predictions for all tasks\n",
    "    age_pred_idx = np.argmax(predictions['age_output'][0])\n",
    "    gender_pred_idx = np.argmax(predictions['gender_output'][0])\n",
    "    race_pred_idx = np.argmax(predictions['race_output'][0])\n",
    "    \n",
    "    age_label = data_processor.age_encoder.inverse_transform([age_pred_idx])[0]\n",
    "    gender_label = data_processor.gender_encoder.inverse_transform([gender_pred_idx])[0]\n",
    "    race_label = data_processor.race_encoder.inverse_transform([race_pred_idx])[0]\n",
    "    \n",
    "    print(f\"Model Predictions:\")\n",
    "    print(f\"  Age: {age_label} (confidence: {predictions['age_output'][0][age_pred_idx]:.3f})\")\n",
    "    print(f\"  Gender: {gender_label} (confidence: {predictions['gender_output'][0][gender_pred_idx]:.3f})\")\n",
    "    print(f\"  Race: {race_label} (confidence: {predictions['race_output'][0][race_pred_idx]:.3f})\")\n",
    "    print()\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Original image (large, top center)\n",
    "    ax_orig = plt.subplot2grid((4, 6), (0, 2), colspan=2, rowspan=2)\n",
    "    ax_orig.imshow(img.numpy().astype('uint8'))\n",
    "    ax_orig.set_title(f'Original Image\\nAge: {age_label} | Gender: {gender_label} | Race: {race_label}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    ax_orig.axis('off')\n",
    "    \n",
    "    # Generate explanations for the specified task\n",
    "    try:\n",
    "        # Grad-CAM\n",
    "        gradcam = GradCAM(model)\n",
    "        heatmap, _ = gradcam.generate_gradcam(processed_img, task=task)\n",
    "        \n",
    "        if heatmap is not None:\n",
    "            # Grad-CAM visualization\n",
    "            ax_gradcam = plt.subplot2grid((4, 6), (2, 0), colspan=2)\n",
    "            \n",
    "            # Resize heatmap and create overlay\n",
    "            heatmap_resized = cv2.resize(heatmap, (160, 160))\n",
    "            heatmap_colored = cm.jet(heatmap_resized)[:, :, :3]\n",
    "            overlay = img.numpy().astype('float32') / 255.0\n",
    "            gradcam_overlay = 0.6 * overlay + 0.4 * heatmap_colored\n",
    "            \n",
    "            ax_gradcam.imshow(gradcam_overlay)\n",
    "            ax_gradcam.set_title(f'Grad-CAM: {task.title()}', fontweight='bold')\n",
    "            ax_gradcam.axis('off')\n",
    "        \n",
    "        # LIME explanation\n",
    "        ax_lime = plt.subplot2grid((4, 6), (2, 2), colspan=2)\n",
    "        \n",
    "        def lime_predict_fn(images):\n",
    "            batch = []\n",
    "            for img_lime in images:\n",
    "                processed = tf.cast(img_lime, tf.float32) / 255.0\n",
    "                processed = tf.image.per_image_standardization(processed)\n",
    "                batch.append(processed)\n",
    "            \n",
    "            batch = tf.stack(batch)\n",
    "            preds = model.predict(batch, verbose=0)\n",
    "            \n",
    "            if task == 'age':\n",
    "                return preds['age_output']\n",
    "            elif task == 'gender':\n",
    "                return preds['gender_output']\n",
    "            elif task == 'race':\n",
    "                return preds['race_output']\n",
    "        \n",
    "        explainer = lime_image.LimeImageExplainer()\n",
    "        explanation = explainer.explain_instance(\n",
    "            img.numpy().astype('uint8'),\n",
    "            lime_predict_fn,\n",
    "            top_labels=3,\n",
    "            hide_color=0,\n",
    "            num_samples=500  # Reduced for speed\n",
    "        )\n",
    "        \n",
    "        # Get LIME visualization\n",
    "        if task == 'age':\n",
    "            pred_class = age_pred_idx\n",
    "        elif task == 'gender':\n",
    "            pred_class = gender_pred_idx\n",
    "        elif task == 'race':\n",
    "            pred_class = race_pred_idx\n",
    "            \n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            pred_class, \n",
    "            positive_only=True, \n",
    "            num_features=10, \n",
    "            hide_rest=False\n",
    "        )\n",
    "        \n",
    "        ax_lime.imshow(temp)\n",
    "        ax_lime.set_title(f'LIME: {task.title()}', fontweight='bold')\n",
    "        ax_lime.axis('off')\n",
    "        \n",
    "        # SHAP explanation (simplified version)\n",
    "        ax_shap = plt.subplot2grid((4, 6), (2, 4), colspan=2)\n",
    "        \n",
    "        # For SHAP, we'll create a simpler version due to computational constraints\n",
    "        # Generate random background (in practice, use real background data)\n",
    "        background_sample = np.random.random((10, 160, 160, 3))\n",
    "        \n",
    "        def shap_predict_fn(x):\n",
    "            batch = []\n",
    "            for img_shap in x:\n",
    "                processed = tf.cast(img_shap, tf.float32) / 255.0\n",
    "                processed = tf.image.per_image_standardization(processed)\n",
    "                batch.append(processed)\n",
    "            \n",
    "            batch = tf.stack(batch)\n",
    "            preds = model.predict(batch, verbose=0)\n",
    "            \n",
    "            if task == 'age':\n",
    "                return preds['age_output']\n",
    "            elif task == 'gender':\n",
    "                return preds['gender_output']\n",
    "            elif task == 'race':\n",
    "                return preds['race_output']\n",
    "        \n",
    "        # Simplified SHAP visualization (feature importance map)\n",
    "        # Create a simple gradient-based importance map as SHAP alternative\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(processed_img)\n",
    "            preds = model(processed_img)\n",
    "            \n",
    "            if task == 'age':\n",
    "                loss = preds['age_output'][:, pred_class]\n",
    "            elif task == 'gender':\n",
    "                loss = preds['gender_output'][:, pred_class]\n",
    "            elif task == 'race':\n",
    "                loss = preds['race_output'][:, pred_class]\n",
    "        \n",
    "        grads = tape.gradient(loss, processed_img)\n",
    "        grads = tf.abs(grads[0])\n",
    "        grads_norm = (grads - tf.reduce_min(grads)) / (tf.reduce_max(grads) - tf.reduce_min(grads))\n",
    "        \n",
    "        ax_shap.imshow(grads_norm)\n",
    "        ax_shap.set_title(f'Gradient-based Importance: {task.title()}', fontweight='bold')\n",
    "        ax_shap.axis('off')\n",
    "        \n",
    "        # Prediction confidence bars\n",
    "        ax_conf = plt.subplot2grid((4, 6), (3, 1), colspan=4)\n",
    "        \n",
    "        if task == 'age':\n",
    "            task_preds = predictions['age_output'][0]\n",
    "            task_labels = data_processor.age_encoder.classes_\n",
    "        elif task == 'gender':\n",
    "            task_preds = predictions['gender_output'][0]\n",
    "            task_labels = data_processor.gender_encoder.classes_\n",
    "        elif task == 'race':\n",
    "            task_preds = predictions['race_output'][0]\n",
    "            task_labels = data_processor.race_encoder.classes_\n",
    "        \n",
    "        # Show top predictions\n",
    "        top_k = min(8, len(task_labels))\n",
    "        top_indices = np.argsort(task_preds)[-top_k:][::-1]\n",
    "        top_probs = task_preds[top_indices]\n",
    "        top_label_names = [task_labels[i] for i in top_indices]\n",
    "        \n",
    "        bars = ax_conf.barh(range(len(top_label_names)), top_probs)\n",
    "        ax_conf.set_yticks(range(len(top_label_names)))\n",
    "        ax_conf.set_yticklabels(top_label_names)\n",
    "        ax_conf.set_xlabel('Prediction Confidence')\n",
    "        ax_conf.set_title(f'{task.title()} Prediction Confidence')\n",
    "        \n",
    "        # Color the predicted class differently\n",
    "        bars[0].set_color('red')\n",
    "        for i in range(1, len(bars)):\n",
    "            bars[i].set_color('skyblue')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating explanations: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_interpretability(model, data_processor, image_path, tasks=['age', 'gender', 'race']):\n",
    "    \"\"\"Test interpretability for all tasks\"\"\"\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Testing interpretability on: {image_path}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for task in tasks:\n",
    "        print(f\"\\n{'='*20} ANALYZING TASK: {task.upper()} {'='*20}\")\n",
    "        \n",
    "        try:\n",
    "            # Generate comprehensive explanation\n",
    "            explain_prediction_comprehensive(model, data_processor, image_path, task=task)\n",
    "            print(f\"Task {task} explanation completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Task {task} explanation failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM5nJ9pyH/KBim4w591wgqE",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1QWnY7-M1agv-s49cd3xZqMZqsRkQlEls",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

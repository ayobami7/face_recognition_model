{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python27\\python.exe: No module named venv\n"
     ]
    }
   ],
   "source": [
    "!python -m venv tfenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q scipy opencv-python scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40520,
     "status": "ok",
     "timestamp": 1754895834445,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "3YJUz3grE1jt",
    "outputId": "39585519-2ff6-43c1-e907-104502b29eee"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow tensorflow-addons tensorflow-hub tensorflow-datasets\n",
    "!pip install  gdown matplotlib seaborn \n",
    "!pip install keras-facenet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, losses, metrics, Model\n",
    "# import tensorflow_hub as hub\n",
    "from keras_facenet import FaceNet # type: ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import gdown\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from google.colab import drive, files\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1466,
     "status": "ok",
     "timestamp": 1754896145023,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "TcEuppv89pwx",
    "outputId": "2c950862-e39d-4086-b4aa-8c3d34b4f658"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "DATASET_PATH = \"C:/Users/aa24afl/Downloads/FairFace\"\n",
    "# DATASET_PATH = \"C:/Users/DELL/Downloads/datasets/FairFace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41361,
     "status": "ok",
     "timestamp": 1754896195976,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "yb7BNSQsAh1j",
    "outputId": "c92cea7f-1068-488e-ffe4-c1cc8dc9e8ab"
   },
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(\"Path exists.\")\n",
    "else:\n",
    "    print(\"Path does not exist.\")\n",
    "\n",
    "# Verify dataset structure\n",
    "expected_files = [\n",
    "    \"train_labels.csv\",\n",
    "    \"val_labels.csv\",\n",
    "    \"train/\",\n",
    "    \"val/\"\n",
    "]\n",
    "\n",
    "print(f\"Loading dataset from: {DATASET_PATH}\")\n",
    "\n",
    "# Check if all required files/folders exist\n",
    "missing_files = []\n",
    "for item in expected_files:\n",
    "    if not os.path.exists(os.path.join(DATASET_PATH, item)):\n",
    "        missing_files.append(item)\n",
    "\n",
    "if missing_files:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset incomplete. Missing: {missing_files}\\n\"\n",
    "        f\"Expected structure:\\n\"\n",
    "        f\"{DATASET_PATH}/\\n\"\n",
    "        f\"├── train_labels.csv\\n\"\n",
    "        f\"├── val_labels.csv\\n\"\n",
    "        f\"├── train/ [contains images]\\n\"\n",
    "        f\"└── val/   [contains images]\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Set paths for data loading\n",
    "TRAIN_CSV_PATH = os.path.join(DATASET_PATH, \"train_labels.csv\")\n",
    "VAL_CSV_PATH = os.path.join(DATASET_PATH, \"val_labels.csv\")\n",
    "TRAIN_IMG_DIR = os.path.join(DATASET_PATH, \"train\")\n",
    "VAL_IMG_DIR = os.path.join(DATASET_PATH, \"val\")\n",
    "\n",
    "print(\"\\nDataset structure verified:\")\n",
    "print(f\"Training CSV:   {TRAIN_CSV_PATH}\")\n",
    "print(f\"Validation CSV: {VAL_CSV_PATH}\")\n",
    "print(f\"Training images: {TRAIN_IMG_DIR} ({len(os.listdir(TRAIN_IMG_DIR))} files)\")\n",
    "print(f\"Validation images: {VAL_IMG_DIR} ({len(os.listdir(VAL_IMG_DIR))} files)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1754896457884,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "WONN5P3SVJmf"
   },
   "outputs": [],
   "source": [
    "class FairFaceDataProcessor:\n",
    "    def __init__(self, csv_path, img_dir, img_size=160, sample_size=None, is_validation=False):\n",
    "        self.img_size = img_size\n",
    "        self.img_dir = img_dir\n",
    "        self.is_validation = is_validation\n",
    "\n",
    "        # Load CSV data\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filter dataset to keep only valid age groups\n",
    "        valid_age_groups = [\n",
    "            '0-2', '3-9', '10-19', '20-29', '30-39',\n",
    "            '40-49', '50-59', '60-69', 'more than 70'\n",
    "        ]\n",
    "        original_len = len(self.df)\n",
    "        self.df = self.df[self.df['age'].isin(valid_age_groups)].reset_index(drop=True)\n",
    "        print(f\"Removed {original_len - len(self.df)} rows with invalid age groups\")\n",
    "\n",
    "        # Sample data if specified\n",
    "        if sample_size and sample_size < len(self.df):\n",
    "            self.df = self.df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "            print(f\"Sampled {'validation' if is_validation else 'training'}: {len(self.df)} samples\")\n",
    "\n",
    "        # Initialize label encoders only once (use training data to fit)\n",
    "        if not hasattr(self, 'age_encoder'):\n",
    "            self.age_encoder = LabelEncoder()\n",
    "            self.gender_encoder = LabelEncoder()\n",
    "            self.race_encoder = LabelEncoder()\n",
    "\n",
    "            # Fit encoders on this dataset\n",
    "            self.age_encoder.fit(self.df['age'])\n",
    "            self.gender_encoder.fit(self.df['gender'])\n",
    "            self.race_encoder.fit(self.df['race'])\n",
    "\n",
    "        # Encode labels\n",
    "        self.df['age_encoded'] = self.age_encoder.transform(self.df['age'])\n",
    "        # self.df['gender_encoded'] = self.gender_encoder.transform(self.df['gender'])\n",
    "        self.df['gender_encoded'] = (self.df['gender'] == 'Male').astype(int)\n",
    "        self.df['race_encoded'] = self.race_encoder.transform(self.df['race'])\n",
    "\n",
    "        self.num_classes = {\n",
    "            'age': len(self.age_encoder.classes_),\n",
    "            'gender': len(self.gender_encoder.classes_),\n",
    "            'race': len(self.race_encoder.classes_)\n",
    "        }\n",
    "\n",
    "        print(f\"Classes - Age: {self.num_classes['age']}, Gender: {self.num_classes['gender']}, Race: {self.num_classes['race']}\")\n",
    "        if not is_validation:\n",
    "            print(f\"Age groups: {list(self.age_encoder.classes_)}\")\n",
    "            print(f\"Gender groups: {list(self.gender_encoder.classes_)}\")\n",
    "            print(f\"Race groups: {list(self.race_encoder.classes_)}\")\n",
    "\n",
    "    def filter_missing_files(self):\n",
    "        \"\"\"Filter out rows where image files don't exist\"\"\"\n",
    "        print(f\"Original dataset size: {len(self.df)}\")\n",
    "\n",
    "        # Check which files exist\n",
    "        existing_files = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_path = os.path.join(self.img_dir, row['file'])\n",
    "            if os.path.exists(img_path):\n",
    "                existing_files.append(idx)\n",
    "\n",
    "        # Filter dataframe to keep only existing files\n",
    "        self.df = self.df.loc[existing_files].reset_index(drop=True)\n",
    "\n",
    "        print(f\"Filtered dataset size: {len(self.df)}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def load_and_preprocess_image(self, image_path, augment=False):\n",
    "        \"\"\"Load and preprocess single image\"\"\"\n",
    "        try:\n",
    "            # Check if file exists\n",
    "            if not tf.io.gfile.exists(image_path):\n",
    "                print(f\"Warning: File not found: {image_path}\")\n",
    "                return tf.zeros([self.img_size, self.img_size, 3], dtype=tf.float32)\n",
    "\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_image(image, channels=3)\n",
    "            image = tf.image.resize(image, [self.img_size, self.img_size])\n",
    "            image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "            if augment:\n",
    "                # Data augmentation\n",
    "                image = tf.image.random_flip_left_right(image)\n",
    "                image = tf.image.random_brightness(image, 0.1)\n",
    "                image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "                image = tf.image.random_saturation(image, 0.9, 1.1)\n",
    "                image = tf.image.random_hue(image, 0.05)\n",
    "\n",
    "            # Normalize using ImageNet statistics (for FaceNet compatibility)\n",
    "            image = tf.image.per_image_standardization(image)\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Return black image if file not found\n",
    "            return tf.zeros([self.img_size, self.img_size, 3], dtype=tf.float32)\n",
    "\n",
    "    def create_dataset(self, batch_size=32, augment=False, shuffle=True):\n",
    "        \"\"\"Create TensorFlow dataset\"\"\"\n",
    "        def generator():\n",
    "            indices = np.arange(len(self.df))\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "            for idx in indices:\n",
    "                row = self.df.iloc[idx]\n",
    "\n",
    "                img_path = os.path.join(self.img_dir, row['file'])\n",
    "\n",
    "                image = self.load_and_preprocess_image(img_path, augment)\n",
    "\n",
    "                yield (\n",
    "                    image,\n",
    "                    {\n",
    "                        'age_output': tf.cast(row['age_encoded'], dtype=tf.int32),\n",
    "                        'gender_output': tf.cast(row['gender_encoded'], dtype=tf.int32),\n",
    "                        'race_output': tf.cast(row['race_encoded'], dtype=tf.int32)\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Create dataset\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(self.img_size, self.img_size, 3), dtype=tf.float32),\n",
    "                {\n",
    "                    'age_output': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "                    'gender_output': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "                    'race_output': tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1754896206318,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "1drJhus-PYHr"
   },
   "outputs": [],
   "source": [
    "class FaceNetMultiTask(tf.keras.Model):\n",
    "    def __init__(self, num_age_classes, num_gender_classes, num_race_classes,\n",
    "                 freeze_backbone=False):\n",
    "        super(FaceNetMultiTask, self).__init__()\n",
    "\n",
    "        self.backbone = FaceNet().model\n",
    "\n",
    "        # Freeze backbone\n",
    "        if freeze_backbone:\n",
    "            self.backbone.trainable = False\n",
    "\n",
    "        # # Classification heads\n",
    "        # self.age_classifier = tf.keras.Sequential([\n",
    "        #     layers.Dense(512, activation='relu'),\n",
    "        #     layers.Dropout(0.7),\n",
    "        #     layers.Dense(128, activation='relu'),\n",
    "        #     layers.Dense(num_age_classes, activation='softmax', name='age_output')\n",
    "        # ], name='age_head')\n",
    "\n",
    "        # self.gender_classifier = tf.keras.Sequential([\n",
    "        #     layers.Dense(512, activation='relu'),\n",
    "        #     layers.Dropout(0.7),\n",
    "        #     layers.Dense(128, activation='relu'),\n",
    "        #     layers.Dense(1, activation='sigmoid', name='gender_output')\n",
    "        # ], name='gender_head')\n",
    "\n",
    "        # self.race_classifier = tf.keras.Sequential([\n",
    "        #     layers.Dense(512, activation='relu'),\n",
    "        #     layers.Dropout(0.7),\n",
    "        #     layers.Dense(128, activation='relu'),\n",
    "        #     layers.Dense(num_race_classes, activation='softmax', name='race_output')\n",
    "        # ], name='race_head')\n",
    "\n",
    "        # Shared dense layer\n",
    "        self.shared_dense = layers.Dense(512, activation='relu', name='shared_dense')\n",
    "        self.shared_dropout = layers.Dropout(0.7, name='shared_dropout')\n",
    "\n",
    "        # Task-specific classification heads\n",
    "        # age branch\n",
    "        self.age_classifier = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', name='age_dense'),\n",
    "            layers.Dense(num_age_classes, activation='softmax', name='age_output')\n",
    "        ], name='age_head')\n",
    "\n",
    "        # gender branch\n",
    "        self.gender_classifier = tf.keras.Sequential([\n",
    "            layers.Dense(1, activation='sigmoid', name='gender_output')\n",
    "        ], name='gender_head')\n",
    "\n",
    "        # race branch\n",
    "        self.race_classifier = tf.keras.Sequential([\n",
    "            layers.Dense(num_race_classes, activation='softmax', name='race_output')\n",
    "        ], name='race_head')\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Get FaceNet embeddings\n",
    "        embeddings = self.backbone(inputs, training=training)\n",
    "\n",
    "        # Shared processing\n",
    "        shared_features = self.shared_dense(embeddings, training=training)\n",
    "        shared_features = self.shared_dropout(shared_features, training=training)\n",
    "\n",
    "        # Task-specific predictions\n",
    "        age_pred = self.age_classifier(shared_features, training=training)\n",
    "        gender_pred = self.gender_classifier(shared_features, training=training)\n",
    "        race_pred = self.race_classifier(shared_features, training=training)\n",
    "\n",
    "        return {\n",
    "            'age_output': age_pred,\n",
    "            'gender_output': gender_pred,\n",
    "            'race_output': race_pred\n",
    "        }\n",
    "\n",
    "def create_and_compile_model(num_age_classes, num_gender_classes, num_race_classes, freeze_backbone=False):\n",
    "    \"\"\"Create and compile the multi-task model \"\"\"\n",
    "\n",
    "    model = FaceNetMultiTask(\n",
    "        num_age_classes=num_age_classes,\n",
    "        num_gender_classes=num_gender_classes,\n",
    "        num_race_classes=num_race_classes,\n",
    "        freeze_backbone=freeze_backbone\n",
    "    )\n",
    "\n",
    "    # Build the model\n",
    "    model.build((None, 160, 160, 3))\n",
    "\n",
    "    # Optimizer with learning rate schedule\n",
    "    initial_lr = 0.001\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=initial_lr),\n",
    "        loss={\n",
    "            'age_output': losses.SparseCategoricalCrossentropy(),\n",
    "            'gender_output': tf.keras.losses.BinaryCrossentropy(),\n",
    "            'race_output': losses.SparseCategoricalCrossentropy()\n",
    "        },\n",
    "        loss_weights={\n",
    "            'age_output': 1.0,\n",
    "            'gender_output': 1.0,\n",
    "            'race_output': 1.0\n",
    "        },\n",
    "        metrics={\n",
    "            'age_output': ['sparse_categorical_accuracy'],\n",
    "            'gender_output': ['binary_accuracy'],\n",
    "            'race_output': ['sparse_categorical_accuracy']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"\\n Model compiled successfully!\")\n",
    "    print(f\"   - Backbone frozen: {freeze_backbone}\")\n",
    "    print(f\"   - Learning rate: {initial_lr}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341269,
     "status": "ok",
     "timestamp": 1754896803647,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "2WTcl-yIykK6",
    "outputId": "fedae64e-41f0-4534-d8c6-547b5ebb1ed3"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 160\n",
    "EPOCHS = 20\n",
    "SAMPLE_SIZE = 30000\n",
    "\n",
    "print(\"Creating training data processor...\")\n",
    "train_processor = FairFaceDataProcessor(\n",
    "    TRAIN_CSV_PATH,\n",
    "    DATASET_PATH,\n",
    "    img_size=IMG_SIZE,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    "    is_validation=False\n",
    ").filter_missing_files()\n",
    "\n",
    "print(\"\\nCreating validation data processor...\")\n",
    "val_processor = FairFaceDataProcessor(\n",
    "    VAL_CSV_PATH,\n",
    "    DATASET_PATH,\n",
    "    img_size=IMG_SIZE,\n",
    "    sample_size=SAMPLE_SIZE//5 if SAMPLE_SIZE else None,\n",
    "    is_validation=True\n",
    ").filter_missing_files()\n",
    "\n",
    "# Copy encoders from training to validation processor\n",
    "val_processor.age_encoder = train_processor.age_encoder\n",
    "val_processor.gender_encoder = train_processor.gender_encoder\n",
    "val_processor.race_encoder = train_processor.race_encoder\n",
    "\n",
    "# Re-encode validation labels with training encoders\n",
    "val_processor.df['age_encoded'] = val_processor.age_encoder.transform(val_processor.df['age'])\n",
    "val_processor.df['gender_encoded'] = val_processor.gender_encoder.transform(val_processor.df['gender'])\n",
    "val_processor.df['race_encoded'] = val_processor.race_encoder.transform(val_processor.df['race'])\n",
    "\n",
    "print(\"\\nCreating datasets...\")\n",
    "train_dataset = train_processor.create_dataset(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = val_processor.create_dataset(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    augment=False,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 7582,
     "status": "ok",
     "timestamp": 1754896811234,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "bv7OlybkARBz",
    "outputId": "7bb5ce51-779d-49f7-cde1-dd7c832d04b9"
   },
   "outputs": [],
   "source": [
    "print(\"Building model...\")\n",
    "model = create_and_compile_model(\n",
    "    num_age_classes=train_processor.num_classes['age'],\n",
    "    num_gender_classes=train_processor.num_classes['gender'],\n",
    "    num_race_classes=train_processor.num_classes['race'],\n",
    "    freeze_backbone=True \n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1754897108153,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "MWotdjMtbOOw"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'best_fairface_facenet_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.CSVLogger('training_log.csv')\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6783,
     "status": "ok",
     "timestamp": 1754897125105,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "9ys2IgG9HiWZ",
    "outputId": "035fdfe4-d78b-4cdb-b4af-7c53ea2381fb"
   },
   "outputs": [],
   "source": [
    "def verify_dataset_structure():\n",
    "    print(\"=== Dataset Structure Verification ===\")\n",
    "\n",
    "    # Check CSV files\n",
    "    train_csv = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    val_csv = pd.read_csv(VAL_CSV_PATH)\n",
    "\n",
    "    print(f\"Training CSV shape: {train_csv.shape}\")\n",
    "    print(f\"Validation CSV shape: {val_csv.shape}\")\n",
    "    print(f\"Training CSV columns: {list(train_csv.columns)}\")\n",
    "\n",
    "    # Check image directories\n",
    "    train_images = os.listdir(TRAIN_IMG_DIR)\n",
    "    val_images = os.listdir(VAL_IMG_DIR) if os.path.exists(VAL_IMG_DIR) else []\n",
    "\n",
    "    print(f\"Training images found: {len(train_images)}\")\n",
    "    print(f\"Validation images found: {len(val_images)}\")\n",
    "\n",
    "    # Check if CSV files match image files\n",
    "    print(\"\\n=== File Matching Check ===\")\n",
    "\n",
    "    # Sample a few files from CSV and check if they exist\n",
    "    sample_files = train_csv['file'].head(10).tolist()\n",
    "    missing_files = []\n",
    "\n",
    "    for file_name in sample_files:\n",
    "        # full_path = os.path.join(TRAIN_IMG_DIR, file_name)\n",
    "        full_path = os.path.join(DATASET_PATH, file_name)\n",
    "        if not os.path.exists(full_path):\n",
    "            missing_files.append(full_path)\n",
    "        else:\n",
    "            print(f\"Found: {full_path}\")\n",
    "\n",
    "    if missing_files:\n",
    "        print(f\"✗ Missing files: {missing_files}\")\n",
    "    else:\n",
    "        print(\"✓ All sampled files found!\")\n",
    "\n",
    "    # Check first few rows of CSV\n",
    "    print(f\"\\nFirst few rows of training CSV:\")\n",
    "    print(train_csv.head())\n",
    "\n",
    "    return len(missing_files) == 0\n",
    "\n",
    "# Run verification\n",
    "dataset_ok = verify_dataset_structure()\n",
    "\n",
    "if dataset_ok:\n",
    "    print(\"\\n✓ Dataset structure looks good! Proceeding with training...\")\n",
    "else:\n",
    "    print(\"\\n✗ Dataset structure issues found. Please check file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "19fY68tkbhW6"
   },
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=20,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwNWKg_bW2Gg"
   },
   "outputs": [],
   "source": [
    "print(\"Available history keys:\", list(history.history.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfeTgSyaEQxk"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Total Loss (Training vs Validation)\n",
    "    ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
    "    ax1.set_title('Total Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Individual Task Losses\n",
    "    ax2.plot(history.history['age_output_loss'], label='Age Train', color='red', linestyle='-')\n",
    "    ax2.plot(history.history['val_age_output_loss'], label='Age Val', color='red', linestyle='--')\n",
    "    ax2.plot(history.history['gender_output_loss'], label='Gender Train', color='green', linestyle='-')\n",
    "    ax2.plot(history.history['val_gender_output_loss'], label='Gender Val', color='green', linestyle='--')\n",
    "    ax2.plot(history.history['race_output_loss'], label='Race Train', color='orange', linestyle='-')\n",
    "    ax2.plot(history.history['val_race_output_loss'], label='Race Val', color='orange', linestyle='--')\n",
    "    ax2.set_title('Individual Task Losses')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Task Accuracies \n",
    "    ax3.plot(history.history['age_output_sparse_categorical_accuracy'], label='Age Train', color='red', linestyle='-')\n",
    "    ax3.plot(history.history['val_age_output_sparse_categorical_accuracy'], label='Age Val', color='red', linestyle='--')\n",
    "    ax3.plot(history.history['gender_output_binary_accuracy'], label='Gender Train', color='green', linestyle='-')\n",
    "    ax3.plot(history.history['val_gender_output_binary_accuracy'], label='Gender Val', color='green', linestyle='--')\n",
    "    ax3.plot(history.history['race_output_sparse_categorical_accuracy'], label='Race Train', color='orange', linestyle='-')\n",
    "    ax3.plot(history.history['val_race_output_sparse_categorical_accuracy'], label='Race Val', color='orange', linestyle='--')\n",
    "    ax3.set_title('Task Accuracies')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True)\n",
    "\n",
    "    # Learning Rate\n",
    "    ax4.plot(history.history['learning_rate'], label='Learning Rate', color='purple')\n",
    "    ax4.set_title('Learning Rate Schedule')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Learning Rate')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True)\n",
    "    ax4.set_yscale('log') \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(\"Final Training Metrics:\")\n",
    "    print(f\"Total Loss: {history.history['loss'][-1]:.4f} | Val Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"Age Loss: {history.history['age_output_loss'][-1]:.4f} | Val: {history.history['val_age_output_loss'][-1]:.4f}\")\n",
    "    print(f\"Gender Loss: {history.history['gender_output_loss'][-1]:.4f} | Val: {history.history['val_gender_output_loss'][-1]:.4f}\")\n",
    "    print(f\"Race Loss: {history.history['race_output_loss'][-1]:.4f} | Val: {history.history['val_race_output_loss'][-1]:.4f}\")\n",
    "    print(f\"Age Accuracy: {history.history['age_output_sparse_categorical_accuracy'][-1]:.4f} | Val: {history.history['val_age_output_sparse_categorical_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Gender Accuracy: {history.history['gender_output_binary_accuracy'][-1]:.4f} | Val: {history.history['val_gender_output_binary_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Race Accuracy: {history.history['race_output_sparse_categorical_accuracy'][-1]:.4f} | Val: {history.history['val_race_output_sparse_categorical_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final Learning Rate: {history.history['learning_rate'][-1]:.2e}\")\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training log\n",
    "df = pd.read_csv('utkface_finetuning_log.csv')\n",
    "\n",
    "# Create comprehensive plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('UTKFace Model Training Progress', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Age Prediction Accuracy\n",
    "axes[0, 0].plot(df['epoch'], df['age_output_sparse_categorical_accuracy'], \n",
    "                'b-', linewidth=2, label='Training Accuracy', marker='o', markersize=4)\n",
    "axes[0, 0].plot(df['epoch'], df['val_age_output_sparse_categorical_accuracy'], \n",
    "                'r-', linewidth=2, label='Validation Accuracy', marker='s', markersize=4)\n",
    "axes[0, 0].set_title('Age Prediction Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_ylim([0.4, 0.9])\n",
    "\n",
    "# 2. Gender Prediction Accuracy\n",
    "axes[0, 1].plot(df['epoch'], df['gender_output_sparse_categorical_accuracy'], \n",
    "                'b-', linewidth=2, label='Training Accuracy', marker='o', markersize=4)\n",
    "axes[0, 1].plot(df['epoch'], df['val_gender_output_sparse_categorical_accuracy'], \n",
    "                'r-', linewidth=2, label='Validation Accuracy', marker='s', markersize=4)\n",
    "axes[0, 1].set_title('Gender Prediction Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_ylim([0.8, 1.0])\n",
    "\n",
    "# 3. Race Prediction Accuracy\n",
    "axes[1, 0].plot(df['epoch'], df['race_output_sparse_categorical_accuracy'], \n",
    "                'b-', linewidth=2, label='Training Accuracy', marker='o', markersize=4)\n",
    "axes[1, 0].plot(df['epoch'], df['val_race_output_sparse_categorical_accuracy'], \n",
    "                'r-', linewidth=2, label='Validation Accuracy', marker='s', markersize=4)\n",
    "axes[1, 0].set_title('Race Prediction Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim([0.6, 1.0])\n",
    "\n",
    "# 4. Overall Loss\n",
    "axes[1, 1].plot(df['epoch'], df['loss'], \n",
    "                'b-', linewidth=2, label='Training Loss', marker='o', markersize=4)\n",
    "axes[1, 1].plot(df['epoch'], df['val_loss'], \n",
    "                'r-', linewidth=2, label='Validation Loss', marker='s', markersize=4)\n",
    "axes[1, 1].set_title('Overall Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final performance summary\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_epoch = df.iloc[-1]\n",
    "print(f\"Epoch: {int(final_epoch['epoch'])}\")\n",
    "print(f\"Learning Rate: {final_epoch['learning_rate']:.2e}\")\n",
    "print()\n",
    "\n",
    "print(\"TRAINING ACCURACIES:\")\n",
    "print(f\"  Age:    {final_epoch['age_output_sparse_categorical_accuracy']:.4f} ({final_epoch['age_output_sparse_categorical_accuracy']*100:.2f}%)\")\n",
    "print(f\"  Gender: {final_epoch['gender_output_sparse_categorical_accuracy']:.4f} ({final_epoch['gender_output_sparse_categorical_accuracy']*100:.2f}%)\")\n",
    "print(f\"  Race:   {final_epoch['race_output_sparse_categorical_accuracy']:.4f} ({final_epoch['race_output_sparse_categorical_accuracy']*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "print(\"VALIDATION ACCURACIES:\")\n",
    "print(f\"  Age:    {final_epoch['val_age_output_sparse_categorical_accuracy']:.4f} ({final_epoch['val_age_output_sparse_categorical_accuracy']*100:.2f}%)\")\n",
    "print(f\"  Gender: {final_epoch['val_gender_output_sparse_categorical_accuracy']:.4f} ({final_epoch['val_gender_output_sparse_categorical_accuracy']*100:.2f}%)\")\n",
    "print(f\"  Race:   {final_epoch['val_race_output_sparse_categorical_accuracy']:.4f} ({final_epoch['val_race_output_sparse_categorical_accuracy']*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "print(\"LOSSES:\")\n",
    "print(f\"  Training Loss:   {final_epoch['loss']:.4f}\")\n",
    "print(f\"  Validation Loss: {final_epoch['val_loss']:.4f}\")\n",
    "\n",
    "# Calculate improvement from first to last epoch\n",
    "first_epoch = df.iloc[0]\n",
    "print()\n",
    "print(\"IMPROVEMENT FROM EPOCH 0 TO FINAL EPOCH:\")\n",
    "print(f\"  Age Accuracy:    {(final_epoch['val_age_output_sparse_categorical_accuracy'] - first_epoch['val_age_output_sparse_categorical_accuracy'])*100:.2f}% points\")\n",
    "print(f\"  Gender Accuracy: {(final_epoch['val_gender_output_sparse_categorical_accuracy'] - first_epoch['val_gender_output_sparse_categorical_accuracy'])*100:.2f}% points\")\n",
    "print(f\"  Race Accuracy:   {(final_epoch['val_race_output_sparse_categorical_accuracy'] - first_epoch['val_race_output_sparse_categorical_accuracy'])*100:.2f}% points\")\n",
    "\n",
    "# Check for overfitting\n",
    "print()\n",
    "print(\"OVERFITTING ANALYSIS:\")\n",
    "for task in ['age', 'gender', 'race']:\n",
    "    train_acc = final_epoch[f'{task}_output_sparse_categorical_accuracy']\n",
    "    val_acc = final_epoch[f'val_{task}_output_sparse_categorical_accuracy']\n",
    "    gap = (train_acc - val_acc) * 100\n",
    "    \n",
    "    if gap > 5:\n",
    "        status = \"⚠️  Potential overfitting\"\n",
    "    elif gap > 2:\n",
    "        status = \"⚡ Slight overfitting\"\n",
    "    else:\n",
    "        status = \"✅ Good generalization\"\n",
    "    \n",
    "    print(f\"  {task.capitalize():6}: Train-Val gap = {gap:.2f}% - {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "A5bCJhEpWFdK"
   },
   "outputs": [],
   "source": [
    "def predict_sample(model, img_path, train_processor, img_size=(160, 160)):\n",
    "    \"\"\"\n",
    "    Predict demographics for a single image\n",
    "    \"\"\"\n",
    "    # Load and preprocess image - matching training preprocessing\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, img_size)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "    # Apply same normalization as training (ImageNet standardization)\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    img = tf.expand_dims(img, axis=0)  # Add batch dim\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(img, verbose=0)\n",
    "\n",
    "    # Extract predictions - model returns a dictionary\n",
    "    age_pred = np.argmax(preds['age_output'][0])\n",
    "    gender_pred = np.argmax(preds['gender_output'][0])\n",
    "    race_pred = np.argmax(preds['race_output'][0])\n",
    "\n",
    "    # Decode labels using the training processor encoders\n",
    "    age_label = train_processor.age_encoder.inverse_transform([age_pred])[0]\n",
    "    gender_label = train_processor.gender_encoder.inverse_transform([gender_pred])[0]\n",
    "    race_label = train_processor.race_encoder.inverse_transform([race_pred])[0]\n",
    "\n",
    "    # Display - load original image for display\n",
    "    display_img = tf.io.read_file(img_path)\n",
    "    display_img = tf.image.decode_image(display_img, channels=3)\n",
    "    display_img = tf.image.resize(display_img, img_size)\n",
    "    display_img = tf.cast(display_img, tf.float32) / 255.0\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(display_img)\n",
    "    plt.title(f\"Predictions:\\nAge: {age_label}\\nGender: {gender_label}\\nRace: {race_label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return age_label, gender_label, race_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rnTpCSV1WdZC"
   },
   "outputs": [],
   "source": [
    "def test_predictions(model, train_processor, num_samples=3):\n",
    "    \"\"\"Test predictions on random samples from filtered training data\"\"\"\n",
    "\n",
    "    # Get some sample files from the filtered training data\n",
    "    sample_indices = np.random.choice(len(train_processor.df), num_samples, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        print(f\"\\n=== Sample {i+1} ===\")\n",
    "        row = train_processor.df.iloc[idx]\n",
    "        img_path = os.path.join(train_processor.img_dir, row['file'])\n",
    "\n",
    "        # True labels\n",
    "        true_age = row['age']\n",
    "        true_gender = row['gender']\n",
    "        true_race = row['race']\n",
    "\n",
    "        print(f\"True labels - Age: {true_age}, Gender: {true_gender}, Race: {true_race}\")\n",
    "\n",
    "        # Predict\n",
    "        pred_age, pred_gender, pred_race = predict_sample(model, img_path, train_processor)\n",
    "\n",
    "        # Compare\n",
    "        print(f\"Predicted - Age: {pred_age}, Gender: {pred_gender}, Race: {pred_race}\")\n",
    "        print(f\"Correct - Age: {true_age == pred_age}, Gender: {true_gender == pred_gender}, Race: {true_race == pred_race}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_utkface_facenet_finetuned_model.h5')\n",
    "evaluate_model(model, val_dataset, val_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "admPSvGGWOPj"
   },
   "outputs": [],
   "source": [
    "test_predictions(model, train_processor, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 172946,
     "status": "aborted",
     "timestamp": 1754895966752,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "BEU-ZGsXWRoh"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lime shap tf-explain alibi opencv-python scikit-image slicer lazy_loader numba cloudpickle spacy transformers attrs dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 172948,
     "status": "aborted",
     "timestamp": 1754895966754,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "4J2u7vOMWJaF"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from skimage.segmentation import quickshift\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LIME\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "\n",
    "# SHAP\n",
    "import shap\n",
    "\n",
    "# TF-Explain\n",
    "import tf_explain\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "from tf_explain.core.integrated_gradients import IntegratedGradients as TFIntegratedGradients\n",
    "from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity\n",
    "\n",
    "# Alibi\n",
    "# from alibi.explainers import IntegratedGradients as AlibiIG\n",
    "\n",
    "print(\"✅ All packages installed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 172949,
     "status": "aborted",
     "timestamp": 1754895966756,
     "user": {
      "displayName": "Ayobami Adeyemo",
      "userId": "07870659355035613187"
     },
     "user_tz": -60
    },
    "id": "LOvD716QWgSZ"
   },
   "outputs": [],
   "source": [
    "class TensorFlowModelExplainer:\n",
    "    def __init__(self, model, data_processor, task='age_output'):\n",
    "        self.model = model\n",
    "        self.data_processor = data_processor\n",
    "        self.task = task\n",
    "        \n",
    "        if task == 'age_output':\n",
    "            self.label_encoder = data_processor.age_encoder\n",
    "        elif task == 'gender_output':\n",
    "            self.label_encoder = data_processor.gender_encoder\n",
    "        elif task == 'race_output':\n",
    "            self.label_encoder = data_processor.race_encoder\n",
    "        \n",
    "        print(f\"Explainer ready for {task}. Classes: {list(self.label_encoder.classes_)}\")\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        try:\n",
    "            image = tf.io.read_file(image_path)\n",
    "            image = tf.image.decode_image(image, channels=3)\n",
    "            image = tf.image.resize(image, [160, 160])\n",
    "            image = tf.cast(image, tf.float32) / 255.0\n",
    "            image = tf.image.per_image_standardization(image)\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            return tf.zeros([160, 160, 3], dtype=tf.float32)\n",
    "    \n",
    "    def predict_proba(self, images):\n",
    "        \"\"\"Predict probabilities for LIME\"\"\"\n",
    "        if not isinstance(images, tf.Tensor):\n",
    "            if images.ndim == 3:  \n",
    "                images = images[np.newaxis, ...]\n",
    "            images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "            \n",
    "            # Normalize if needed\n",
    "            if tf.reduce_max(images) > 1.0:\n",
    "                images = images / 255.0\n",
    "            \n",
    "            # Apply per-image standardization (matching training preprocessing)\n",
    "            standardized_images = []\n",
    "            for i in range(images.shape[0]):\n",
    "                img = tf.image.per_image_standardization(images[i])\n",
    "                standardized_images.append(img)\n",
    "            images = tf.stack(standardized_images)\n",
    "        \n",
    "        predictions = self.model(images, training=False)\n",
    "        \n",
    "        # Handle multi-task model output\n",
    "        if isinstance(predictions, dict):\n",
    "            task_pred = predictions[self.task]\n",
    "        else:\n",
    "            task_pred = predictions\n",
    "            \n",
    "        # Apply softmax for classification tasks (except binary gender)\n",
    "        if self.task == 'gender_output':\n",
    "            # Binary classification - use sigmoid output directly\n",
    "            probs = task_pred\n",
    "            # Convert to 2-class format for LIME\n",
    "            probs = tf.concat([1-probs, probs], axis=1)\n",
    "        else:\n",
    "            # Multi-class classification - apply softmax\n",
    "            probs = tf.nn.softmax(task_pred, axis=1)\n",
    "            \n",
    "        return probs.numpy()\n",
    "    \n",
    "    def get_single_prediction(self, image_path):\n",
    "        \"\"\"Get prediction for a single image\"\"\"\n",
    "        image = self.preprocess_image(image_path)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        predictions = self.model(image, training=False)\n",
    "        \n",
    "        # Handle multi-task model output\n",
    "        if isinstance(predictions, dict):\n",
    "            task_pred = predictions[self.task]\n",
    "        else:\n",
    "            task_pred = predictions\n",
    "        \n",
    "        if self.task == 'gender_output':\n",
    "            # Binary classification\n",
    "            prob = tf.nn.sigmoid(task_pred)[0, 0].numpy()\n",
    "            pred_class = int(prob > 0.5)\n",
    "            confidence = prob if pred_class == 1 else (1 - prob)\n",
    "            all_probs = [1-prob, prob]\n",
    "        else:\n",
    "            # Multi-class classification\n",
    "            probs = tf.nn.softmax(task_pred, axis=1)\n",
    "            pred_class = tf.argmax(probs, axis=1)[0].numpy()\n",
    "            confidence = probs[0, pred_class].numpy()\n",
    "            all_probs = probs[0].numpy()\n",
    "        \n",
    "        label = self.label_encoder.inverse_transform([pred_class])[0]\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': pred_class,\n",
    "            'predicted_label': label,\n",
    "            'confidence': confidence,\n",
    "            'all_probabilities': all_probs,\n",
    "            'class_names': list(self.label_encoder.classes_),\n",
    "        }\n",
    "\n",
    "print(\"TensorFlowModelExplainer class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorFlowLIMEExplainer:\n",
    "    def __init__(self, model_explainer):\n",
    "        self.model_explainer = model_explainer\n",
    "        self.explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "    def explain_and_visualize(self, image_path, num_samples=1000, top_classes=3, num_features=10):\n",
    "        \"\"\"Run LIME explanation and visualize results\"\"\"\n",
    "        \n",
    "        # Load image for display\n",
    "        image_pil = Image.open(image_path).convert('RGB')\n",
    "        image_np = np.array(image_pil.resize((160, 160)))\n",
    "\n",
    "        # Get prediction info\n",
    "        pred_info = self.model_explainer.get_single_prediction(image_path)\n",
    "        print(f\"\\nPrediction: {pred_info['predicted_label']} (confidence: {pred_info['confidence']:.3f})\")\n",
    "        \n",
    "        print(\"All class probabilities:\")\n",
    "        for i, label in enumerate(pred_info['class_names']):\n",
    "            print(f\"- {label}: {pred_info['all_probabilities'][i]:.3f}\")\n",
    "\n",
    "        # LIME prediction function\n",
    "        def lime_predict_fn(images):\n",
    "            \"\"\"Prediction function for LIME\"\"\"\n",
    "            return self.model_explainer.predict_proba(images)\n",
    "\n",
    "        # Run LIME explanation\n",
    "        print(f\"\\nRunning LIME explanation with {num_samples} samples...\")\n",
    "        explanation = self.explainer.explain_instance(\n",
    "            image_np, \n",
    "            lime_predict_fn,\n",
    "            top_labels=min(top_classes, len(pred_info['class_names'])),\n",
    "            num_samples=num_samples,\n",
    "            segmentation_fn=SegmentationAlgorithm(\n",
    "                'quickshift', \n",
    "                kernel_size=4, \n",
    "                max_dist=200, \n",
    "                ratio=0.2\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Visualization\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        # Original image\n",
    "        axes[0].imshow(image_np)\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # LIME overlay for predicted class\n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            pred_info['predicted_class'], \n",
    "            positive_only=False, \n",
    "            num_features=num_features, \n",
    "            hide_rest=False\n",
    "        )\n",
    "        axes[1].imshow(temp)\n",
    "        axes[1].set_title(f\"LIME Explanation\\n{pred_info['predicted_label']}\")\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        # Contribution mask\n",
    "        axes[2].imshow(mask, cmap='RdYlBu_r')\n",
    "        axes[2].set_title(\"Feature Importance\\n(Red=Negative, Blue=Positive)\")\n",
    "        axes[2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Show top contributing superpixels\n",
    "        print(f\"\\nTop {num_features} superpixel contributions for '{pred_info['predicted_label']}':\")\n",
    "        local_exp = explanation.local_exp[pred_info['predicted_class']]\n",
    "        for i, (sp_id, weight) in enumerate(sorted(local_exp, key=lambda x: -abs(x[1]))[:num_features]):\n",
    "            direction = \"positive\" if weight > 0 else \"negative\"\n",
    "            print(f\"{i+1}. Superpixel {sp_id}: {weight:.3f} ({direction})\")\n",
    "\n",
    "        return explanation, pred_info, image_np\n",
    "\n",
    "print(\"TensorFlowLIMEExplainer class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorFlowSHAPExplainer:\n",
    "    def __init__(self, model_explainer, background_images=None):\n",
    "        self.model_explainer = model_explainer\n",
    "        self.model = model_explainer.model\n",
    "        self.task = model_explainer.task\n",
    "        \n",
    "        # If no background images provided, create a simple baseline\n",
    "        if background_images is None:\n",
    "            print(\"No background images provided, using zero baseline\")\n",
    "            self.background = np.zeros((1, 160, 160, 3))\n",
    "        else:\n",
    "            self.background = background_images\n",
    "            \n",
    "        # Create a wrapper function for SHAP\n",
    "        def model_wrapper(x):\n",
    "            predictions = self.model(x, training=False)\n",
    "            if isinstance(predictions, dict):\n",
    "                task_pred = predictions[self.task]\n",
    "            else:\n",
    "                task_pred = predictions\n",
    "                \n",
    "            # Convert to probabilities\n",
    "            if self.task == 'gender_output':\n",
    "                probs = tf.nn.sigmoid(task_pred)\n",
    "                # Convert to 2-class format\n",
    "                probs = tf.concat([1-probs, probs], axis=1)\n",
    "            else:\n",
    "                probs = tf.nn.softmax(task_pred, axis=1)\n",
    "            return probs\n",
    "        \n",
    "        self.model_wrapper = model_wrapper\n",
    "        \n",
    "        try:\n",
    "            self.explainer = shap.DeepExplainer(self.model_wrapper, self.background)\n",
    "            print(f\"SHAP explainer initialized for {self.task}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to initialize SHAP explainer: {e}\")\n",
    "            self.explainer = None\n",
    "    \n",
    "    def explain_and_visualize(self, image_path, max_evals=100):\n",
    "        \"\"\"Generate and visualize SHAP values\"\"\"\n",
    "        \n",
    "        if self.explainer is None:\n",
    "            print(\"SHAP explainer not available\")\n",
    "            return None, None, None\n",
    "            \n",
    "        # Load and preprocess image\n",
    "        image = self.model_explainer.preprocess_image(image_path)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        \n",
    "        pred_info = self.model_explainer.get_single_prediction(image_path)\n",
    "        print(f\"SHAP for: {pred_info['predicted_label']} (confidence: {pred_info['confidence']:.3f})\")\n",
    "        \n",
    "        try:\n",
    "            # Calculate SHAP values\n",
    "            print(f\"Computing SHAP values (max_evals={max_evals})...\")\n",
    "            shap_values = self.explainer.shap_values(image.numpy(), max_evals=max_evals)\n",
    "            \n",
    "            # SHAP returns values for each class, get the predicted class\n",
    "            if isinstance(shap_values, list):\n",
    "                shap_for_pred = shap_values[pred_info['predicted_class']][0]\n",
    "            else:\n",
    "                shap_for_pred = shap_values[0]\n",
    "            \n",
    "            # Create visualizations\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "            \n",
    "            # Original image\n",
    "            display_img = tf.io.read_file(image_path)\n",
    "            display_img = tf.image.decode_image(display_img, channels=3)\n",
    "            display_img = tf.image.resize(display_img, [160, 160])\n",
    "            display_img = tf.cast(display_img, tf.float32) / 255.0\n",
    "            \n",
    "            axes[0].imshow(display_img)\n",
    "            axes[0].set_title(\"Original Image\")\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # SHAP values for each channel\n",
    "            for i, channel in enumerate(['Red', 'Green', 'Blue']):\n",
    "                shap_channel = shap_for_pred[:, :, i]\n",
    "                im = axes[i+1].imshow(shap_channel, cmap='RdBu_r', vmin=-np.max(np.abs(shap_channel)), vmax=np.max(np.abs(shap_channel)))\n",
    "                axes[i+1].set_title(f'SHAP - {channel} Channel\\n{pred_info[\"predicted_label\"]}')\n",
    "                axes[i+1].axis('off')\n",
    "                plt.colorbar(im, ax=axes[i+1], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Overall importance heatmap\n",
    "            shap_sum = np.sum(np.abs(shap_for_pred), axis=-1)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(shap_sum, cmap='Reds')\n",
    "            plt.title(f\"SHAP Overall Importance\\n{pred_info['predicted_label']}\")\n",
    "            plt.colorbar()\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            return shap_values, pred_info, image\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"SHAP calculation failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None, pred_info, image\n",
    "\n",
    "print(\"TensorFlowSHAPExplainer class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_background_images(data_processor, num_images=10):\n",
    "    \"\"\"Create background images for SHAP from validation data\"\"\"\n",
    "    \n",
    "    background_images = []\n",
    "    \n",
    "    # Get random samples from validation data\n",
    "    sample_indices = np.random.choice(len(data_processor.df), min(num_images, len(data_processor.df)), replace=False)\n",
    "    \n",
    "    print(f\"Creating {len(sample_indices)} background images for SHAP...\")\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        row = data_processor.df.iloc[idx]\n",
    "        img_path = os.path.join(data_processor.img_dir, row['file'])\n",
    "        \n",
    "        try:\n",
    "            img = data_processor.load_and_preprocess_image(img_path, augment=False)\n",
    "            background_images.append(img.numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load background image {img_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not background_images:\n",
    "        print(\"No background images could be loaded, using zero baseline\")\n",
    "        return np.zeros((1, 160, 160, 3))\n",
    "    \n",
    "    background_array = np.array(background_images)\n",
    "    print(f\"Created background dataset with shape: {background_array.shape}\")\n",
    "    \n",
    "    return background_array\n",
    "\n",
    "# Create background images\n",
    "background_imgs = create_background_images(val_processor, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAMExplainer:\n",
    "    \"\"\"Custom GradCAM implementation for multi-task models\"\"\"\n",
    "    \n",
    "    def __init__(self, model_explainer):\n",
    "        self.model_explainer = model_explainer\n",
    "        self.model = model_explainer.model\n",
    "        self.task = model_explainer.task\n",
    "        \n",
    "    def find_target_layer(self):\n",
    "        \"\"\"Find appropriate layer for GradCAM\"\"\"\n",
    "        # Look for convolutional layers in the backbone\n",
    "        target_layer = None\n",
    "        for layer in reversed(self.model.backbone.layers):\n",
    "            if hasattr(layer, 'filters'):  # Conv layer\n",
    "                target_layer = layer\n",
    "                break\n",
    "        \n",
    "        if target_layer is None:\n",
    "            print(\"Warning: No suitable convolutional layer found for GradCAM\")\n",
    "            return None\n",
    "            \n",
    "        return target_layer\n",
    "    \n",
    "    def explain_and_visualize(self, image_path):\n",
    "        \"\"\"Generate and visualize GradCAM heatmap\"\"\"\n",
    "        \n",
    "        target_layer = self.find_target_layer()\n",
    "        if target_layer is None:\n",
    "            print(\"Cannot generate GradCAM: No suitable layer found\")\n",
    "            return None, None, None\n",
    "            \n",
    "        print(f\"Using layer '{target_layer.name}' for GradCAM\")\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        image = self.model_explainer.preprocess_image(image_path)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        \n",
    "        pred_info = self.model_explainer.get_single_prediction(image_path)\n",
    "        print(f\"GradCAM for: {pred_info['predicted_label']} (confidence: {pred_info['confidence']:.3f})\")\n",
    "        \n",
    "        # Create gradient model\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [self.model.backbone.input], \n",
    "            [target_layer.output, self.model.output]\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            conv_outputs, predictions = grad_model(image)\n",
    "            \n",
    "            # Get task-specific prediction\n",
    "            if isinstance(predictions, dict):\n",
    "                task_pred = predictions[self.task]\n",
    "            else:\n",
    "                task_pred = predictions\n",
    "                \n",
    "            # Get the score for predicted class\n",
    "            if self.task == 'gender_output':\n",
    "                loss = task_pred[0, 0]  # Binary output\n",
    "            else:\n",
    "                loss = task_pred[0, pred_info['predicted_class']]\n",
    "        \n",
    "        # Calculate gradients\n",
    "        grads = tape.gradient(loss, conv_outputs)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "        \n",
    "        # Weight the feature maps\n",
    "        conv_outputs = conv_outputs[0]\n",
    "        heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "        heatmap = tf.squeeze(heatmap)\n",
    "        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "        \n",
    "        # Resize heatmap to image size\n",
    "        heatmap_resized = tf.image.resize(\n",
    "            tf.expand_dims(heatmap, -1), \n",
    "            [160, 160]\n",
    "        )\n",
    "        heatmap_resized = tf.squeeze(heatmap_resized)\n",
    "        \n",
    "        # Visualize\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Original image (denormalized for display)\n",
    "        display_img = tf.io.read_file(image_path)\n",
    "        display_img = tf.image.decode_image(display_img, channels=3)\n",
    "        display_img = tf.image.resize(display_img, [160, 160])\n",
    "        display_img = tf.cast(display_img, tf.float32) / 255.0\n",
    "        \n",
    "        axes[0].imshow(display_img)\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Heatmap\n",
    "        axes[1].imshow(heatmap_resized, cmap='jet')\n",
    "        axes[1].set_title(f\"GradCAM Heatmap\\n{pred_info['predicted_label']}\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        axes[2].imshow(display_img)\n",
    "        axes[2].imshow(heatmap_resized, cmap='jet', alpha=0.4)\n",
    "        axes[2].set_title(\"Overlay\")\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return heatmap_resized, pred_info, image\n",
    "\n",
    "print(\"GradCAMExplainer class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_prediction_comprehensive(model, data_processor, image_path, task='age_output', background_images=None):\n",
    "    \"\"\"Run comprehensive explanation for a prediction including SHAP\"\"\"\n",
    "    \n",
    "    print(f\"Explaining {task} prediction for {image_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create model explainer\n",
    "    model_explainer = TensorFlowModelExplainer(model, data_processor, task)\n",
    "    \n",
    "    try:\n",
    "        # LIME Explanation\n",
    "        print(\"\\n1. LIME Explanation:\")\n",
    "        print(\"-\" * 30)\n",
    "        lime_explainer = TensorFlowLIMEExplainer(model_explainer)\n",
    "        lime_explanation, pred_info, img_np = lime_explainer.explain_and_visualize(\n",
    "            image_path, num_samples=500, num_features=8\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"LIME explanation failed: {e}\")\n",
    "        lime_explanation = None\n",
    "    \n",
    "    try:\n",
    "        # GradCAM Explanation\n",
    "        print(\"\\n2. GradCAM Explanation:\")\n",
    "        print(\"-\" * 30)\n",
    "        gradcam_explainer = GradCAMExplainer(model_explainer)\n",
    "        gradcam_heatmap, _, _ = gradcam_explainer.explain_and_visualize(image_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"GradCAM explanation failed: {e}\")\n",
    "        gradcam_heatmap = None\n",
    "    \n",
    "    try:\n",
    "        # SHAP Explanation\n",
    "        print(\"\\n3. SHAP Explanation:\")\n",
    "        print(\"-\" * 30)\n",
    "        shap_explainer = TensorFlowSHAPExplainer(model_explainer, background_images)\n",
    "        shap_values, _, _ = shap_explainer.explain_and_visualize(image_path, max_evals=50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"SHAP explanation failed: {e}\")\n",
    "        shap_values = None\n",
    "    \n",
    "    return {\n",
    "        'lime_explanation': lime_explanation,\n",
    "        'gradcam_heatmap': gradcam_heatmap,\n",
    "        'shap_values': shap_values,\n",
    "        'prediction_info': pred_info if 'pred_info' in locals() else None\n",
    "    }\n",
    "\n",
    "print(\"comprehensive explanation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_interpretability(model, data_processor, image_path, tasks=['age_output', 'gender_output', 'race_output']):\n",
    "    \"\"\"Test interpretability for all tasks\"\"\"\n",
    "    \n",
    "    for task in tasks:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ANALYZING TASK: {task.upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            results = explain_prediction_comprehensive(\n",
    "                model, data_processor, image_path, task=task\n",
    "            )\n",
    "            print(f\"Task {task} explanation completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Task {task} explanation failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "print(\"Test function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image path to analyze\n",
    "IMAGE_PATH = os.path.join(VAL_IMG_DIR, \"1.jpg\")\n",
    "\n",
    "# Check if image exists\n",
    "if os.path.exists(IMAGE_PATH):\n",
    "    print(f\"Image found: {IMAGE_PATH}\")\n",
    "else:\n",
    "    print(f\"Image not found: {IMAGE_PATH}\")\n",
    "    # Try alternative\n",
    "    IMAGE_PATH = os.path.join(DATASET_PATH, \"val\", \"1.jpg\")\n",
    "    if os.path.exists(IMAGE_PATH):\n",
    "        print(f\"Found at alternative path: {IMAGE_PATH}\")\n",
    "    else:\n",
    "        print(\"Please check your image path\")\n",
    "\n",
    "# Test with a single task first (race classification) - now includes SHAP\n",
    "results = explain_prediction_comprehensive(\n",
    "    model, val_processor, IMAGE_PATH, task='race_output', background_images=background_imgs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all tasks for the same image\n",
    "test_interpretability(\n",
    "    model, val_processor, IMAGE_PATH, \n",
    "    tasks=['age_output', 'gender_output', 'race_output']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_interpretability_with_shap(model, data_processor, image_path, background_images, tasks=['age_output', 'gender_output', 'race_output']):\n",
    "    \"\"\"Test interpretability for all tasks including SHAP\"\"\"\n",
    "    \n",
    "    for task in tasks:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ANALYZING TASK: {task.upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            results = explain_prediction_comprehensive(\n",
    "                model, data_processor, image_path, task=task, background_images=background_images\n",
    "            )\n",
    "            print(f\"Task {task} explanation completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Task {task} explanation failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Test all tasks for the same image (now with SHAP)\n",
    "test_interpretability_with_shap(\n",
    "    model, val_processor, IMAGE_PATH, background_imgs,\n",
    "    tasks=['age_output', 'gender_output', 'race_output']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple images\n",
    "val_images = [f for f in os.listdir(VAL_IMG_DIR) if f.endswith(('.jpg', '.png', '.jpeg'))][:3]\n",
    "\n",
    "for img_file in val_images:\n",
    "    img_path = os.path.join(VAL_IMG_DIR, img_file)\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"ANALYZING IMAGE: {img_file}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Test with age prediction for each image\n",
    "    try:\n",
    "        results = explain_prediction_comprehensive(\n",
    "            model, val_processor, img_path, task='age_output'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to analyze {img_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM5nJ9pyH/KBim4w591wgqE",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1QWnY7-M1agv-s49cd3xZqMZqsRkQlEls",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

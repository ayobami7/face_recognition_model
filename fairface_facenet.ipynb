{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YJUz3grE1jt","outputId":"2721ddc5-17ab-4f13-8dd2-8a5a16d784a4","executionInfo":{"status":"ok","timestamp":1754078114838,"user_tz":-60,"elapsed":16990,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras-facenet in /usr/local/lib/python3.11/dist-packages (0.3.2)\n","Requirement already satisfied: mtcnn in /usr/local/lib/python3.11/dist-packages (from keras-facenet) (1.0.0)\n","Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn->keras-facenet) (1.5.1)\n","Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.11/dist-packages (from mtcnn->keras-facenet) (4.4.4)\n"]}],"source":["!pip install -q tensorflow tensorflow-addons tensorflow-hub tensorflow-datasets\n","!pip install -q gdown matplotlib seaborn\n","!pip install keras-facenet\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, models, optimizers, losses, metrics, Model\n","import tensorflow_hub as hub\n","from keras_facenet import FaceNet\n","import pandas as pd\n","import numpy as np\n","import os\n","from pathlib import Path\n","import zipfile\n","import gdown\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab import drive, files\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","DATASET_PATH = \"/content/drive/MyDrive/datasets/FairFace\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcEuppv89pwx","executionInfo":{"status":"ok","timestamp":1754078115808,"user_tz":-60,"elapsed":945,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}},"outputId":"f8970c76-ed1e-421e-bbf6-c6e32fb96f27"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"yb7BNSQsAh1j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754078116113,"user_tz":-60,"elapsed":301,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}},"outputId":"96181445-d2cd-425f-9db2-cf69b801b0fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Path exists.\n","Loading dataset from: /content/drive/MyDrive/datasets/FairFace\n","\n","Dataset structure verified:\n","Training CSV:   /content/drive/MyDrive/datasets/FairFace/train_labels.csv\n","Validation CSV: /content/drive/MyDrive/datasets/FairFace/val_labels.csv\n","Training images: /content/drive/MyDrive/datasets/FairFace/train (26399 files)\n","Validation images: /content/drive/MyDrive/datasets/FairFace/val (0 files)\n"]}],"source":["\n","if os.path.exists(DATASET_PATH):\n","    print(\"Path exists.\")\n","else:\n","    print(\"Path does not exist.\")\n","\n","# Verify dataset structure\n","expected_files = [\n","    \"train_labels.csv\",\n","    \"val_labels.csv\",\n","    \"train/\",\n","    \"val/\"\n","]\n","\n","print(f\"Loading dataset from: {DATASET_PATH}\")\n","\n","# Check if all required files/folders exist\n","missing_files = []\n","for item in expected_files:\n","    if not os.path.exists(os.path.join(DATASET_PATH, item)):\n","        missing_files.append(item)\n","\n","if missing_files:\n","    raise FileNotFoundError(\n","        f\"Dataset incomplete. Missing: {missing_files}\\n\"\n","        f\"Expected structure:\\n\"\n","        f\"{DATASET_PATH}/\\n\"\n","        f\"├── train_labels.csv\\n\"\n","        f\"├── val_labels.csv\\n\"\n","        f\"├── train/ [contains images]\\n\"\n","        f\"└── val/   [contains images]\"\n","    )\n","\n","\n","# Set paths for data loading\n","TRAIN_CSV_PATH = os.path.join(DATASET_PATH, \"train_labels.csv\")\n","VAL_CSV_PATH = os.path.join(DATASET_PATH, \"val_labels.csv\")\n","TRAIN_IMG_DIR = os.path.join(DATASET_PATH, \"train\")\n","VAL_IMG_DIR = os.path.join(DATASET_PATH, \"val\")\n","\n","print(\"\\nDataset structure verified:\")\n","print(f\"Training CSV:   {TRAIN_CSV_PATH}\")\n","print(f\"Validation CSV: {VAL_CSV_PATH}\")\n","print(f\"Training images: {TRAIN_IMG_DIR} ({len(os.listdir(TRAIN_IMG_DIR))} files)\")\n","print(f\"Validation images: {VAL_IMG_DIR} ({len(os.listdir(VAL_IMG_DIR))} files)\")"]},{"cell_type":"code","source":["class FairFaceDataProcessor:\n","    def __init__(self, csv_path, img_dir, img_size=160, sample_size=None, is_validation=False):\n","        self.img_size = img_size\n","        self.img_dir = img_dir\n","        self.is_validation = is_validation\n","\n","        # Load CSV data\n","        self.df = pd.read_csv(csv_path)\n","\n","        # Sample data if specified\n","        if sample_size and sample_size < len(self.df):\n","            self.df = self.df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n","            print(f\"Sampled {'validation' if is_validation else 'training'}: {len(self.df)} samples\")\n","\n","        # Initialize label encoders only once (use training data to fit)\n","        if not hasattr(self, 'age_encoder'):\n","            self.age_encoder = LabelEncoder()\n","            self.gender_encoder = LabelEncoder()\n","            self.race_encoder = LabelEncoder()\n","\n","            # Fit encoders on this dataset\n","            self.age_encoder.fit(self.df['age'])\n","            self.gender_encoder.fit(self.df['gender'])\n","            self.race_encoder.fit(self.df['race'])\n","\n","        # Encode labels\n","        self.df['age_encoded'] = self.age_encoder.transform(self.df['age'])\n","        self.df['gender_encoded'] = self.gender_encoder.transform(self.df['gender'])\n","        self.df['race_encoded'] = self.race_encoder.transform(self.df['race'])\n","\n","        self.num_classes = {\n","            'age': len(self.age_encoder.classes_),\n","            'gender': len(self.gender_encoder.classes_),\n","            'race': len(self.race_encoder.classes_)\n","        }\n","\n","        print(f\"Classes - Age: {self.num_classes['age']}, Gender: {self.num_classes['gender']}, Race: {self.num_classes['race']}\")\n","        if not is_validation:  # Only print once\n","            print(f\"Age groups: {list(self.age_encoder.classes_)}\")\n","            print(f\"Gender groups: {list(self.gender_encoder.classes_)}\")\n","            print(f\"Race groups: {list(self.race_encoder.classes_)}\")\n","\n","    def load_and_preprocess_image(self, image_path, augment=False):\n","        \"\"\"Load and preprocess single image\"\"\"\n","        try:\n","            # Check if file exists\n","            if not tf.io.gfile.exists(image_path):\n","                print(f\"Warning: File not found: {image_path}\")\n","                return tf.zeros([self.img_size, self.img_size, 3], dtype=tf.float32)\n","\n","            image = tf.io.read_file(image_path)\n","            image = tf.image.decode_image(image, channels=3)\n","            image = tf.image.resize(image, [self.img_size, self.img_size])\n","            image = tf.cast(image, tf.float32) / 255.0\n","\n","            if augment:\n","                # Data augmentation\n","                image = tf.image.random_flip_left_right(image)\n","                image = tf.image.random_brightness(image, 0.1)\n","                image = tf.image.random_contrast(image, 0.9, 1.1)\n","                image = tf.image.random_saturation(image, 0.9, 1.1)\n","                image = tf.image.random_hue(image, 0.05)\n","\n","            # Normalize using ImageNet statistics (for FaceNet compatibility)\n","            image = tf.image.per_image_standardization(image)\n","            return image\n","        except Exception as e:\n","            print(f\"Error loading image {image_path}: {e}\")\n","            # Return black image if file not found\n","            return tf.zeros([self.img_size, self.img_size, 3], dtype=tf.float32)\n","\n","    def create_dataset(self, batch_size=32, augment=False, shuffle=True):\n","        \"\"\"Create TensorFlow dataset\"\"\"\n","        def generator():\n","            indices = np.arange(len(self.df))\n","            if shuffle:\n","                np.random.shuffle(indices)\n","\n","            for idx in indices:\n","                row = self.df.iloc[idx]\n","                # Fix the path construction - don't add extra subdirectory\n","                img_path = os.path.join(self.img_dir, row['file'])\n","\n","                # Debug: Print first few paths to verify\n","                if idx < 3:\n","                    print(f\"Loading image from: {img_path}\")\n","                    print(f\"File exists: {os.path.exists(img_path)}\")\n","\n","                image = self.load_and_preprocess_image(img_path, augment)\n","\n","                yield (\n","                    image,\n","                    {\n","                        'age_output': tf.cast(row['age_encoded'], dtype=tf.int32),\n","                        'gender_output': tf.cast(row['gender_encoded'], dtype=tf.int32),\n","                        'race_output': tf.cast(row['race_encoded'], dtype=tf.int32)\n","                    }\n","                )\n","\n","        # Create dataset\n","        dataset = tf.data.Dataset.from_generator(\n","            generator,\n","            output_signature=(\n","                tf.TensorSpec(shape=(self.img_size, self.img_size, 3), dtype=tf.float32),\n","                {\n","                    'age_output': tf.TensorSpec(shape=(), dtype=tf.int32),\n","                    'gender_output': tf.TensorSpec(shape=(), dtype=tf.int32),\n","                    'race_output': tf.TensorSpec(shape=(), dtype=tf.int32)\n","                }\n","            )\n","        )\n","\n","        if shuffle:\n","            dataset = dataset.shuffle(buffer_size=1000)\n","\n","        dataset = dataset.batch(batch_size)\n","        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","        return dataset"],"metadata":{"id":"WONN5P3SVJmf","executionInfo":{"status":"ok","timestamp":1754078116150,"user_tz":-60,"elapsed":16,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class FaceNetMultiTask(tf.keras.Model):\n","    def __init__(self, num_age_classes, num_gender_classes, num_race_classes,\n","                 freeze_backbone=False):\n","        super(FaceNetMultiTask, self).__init__()\n","\n","        #  Load FaceNet backbone\n","        # self.facenet = FaceNet()\n","        # self.facenet_model = self.facenet.model\n","\n","        # # Remove the final layer to get embeddings\n","        # self.backbone = Model(\n","        #     inputs=self.facenet_model.input,\n","        #     outputs=self.facenet_model.layers[-2].output  # Get embeddings before final layer\n","        # )\n","\n","        self.backbone = FaceNet().model\n","\n","        # Freeze backbone if specified\n","        if freeze_backbone:\n","            self.backbone.trainable = False\n","\n","        # Classification heads\n","        self.age_classifier = tf.keras.Sequential([\n","            layers.Dropout(0.5),\n","            layers.Dense(256, activation='relu'),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.3),\n","            layers.Dense(num_age_classes, activation='softmax', name='age_output')\n","        ], name='age_head') # Add name to sequential model\n","\n","        self.gender_classifier = tf.keras.Sequential([\n","            layers.Dropout(0.5),\n","            layers.Dense(128, activation='relu'),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.3),\n","            layers.Dense(num_gender_classes, activation='softmax', name='gender_output')\n","        ], name='gender_head') # Add name to sequential model\n","\n","        self.race_classifier = tf.keras.Sequential([\n","            layers.Dropout(0.5),\n","            layers.Dense(256, activation='relu'),\n","            layers.BatchNormalization(),\n","            layers.Dropout(0.3),\n","            layers.Dense(num_race_classes, activation='softmax', name='race_output')\n","        ], name='race_head') # Add name to sequential model\n","\n","\n","    def call(self, inputs, training=None):\n","        # Get FaceNet embeddings\n","        embeddings = self.backbone(inputs, training=training)\n","\n","        # Multi-task predictions\n","        age_pred = self.age_classifier(embeddings, training=training)\n","        gender_pred = self.gender_classifier(embeddings, training=training)\n","        race_pred = self.race_classifier(embeddings, training=training)\n","\n","        return {\n","            'age_output': age_pred, # Changed key to match data generator and compile\n","            'gender_output': gender_pred, # Changed key to match data generator and compile\n","            'race_output': race_pred # Changed key to match data generator and compile\n","        }\n","\n","def create_and_compile_model(num_age_classes, num_gender_classes, num_race_classes, freeze_backbone=True):\n","    \"\"\"Create and compile the multi-task model with proper loss functions\"\"\"\n","\n","    model = FaceNetMultiTask(\n","        num_age_classes=num_age_classes,\n","        num_gender_classes=num_gender_classes,\n","        num_race_classes=num_race_classes,\n","        freeze_backbone=freeze_backbone\n","    )\n","\n","    # Build the model\n","    model.build((None, 160, 160, 3))\n","\n","    # Optimizer with learning rate schedule\n","    initial_lr = 0.001\n","    optimizer = optimizers.AdamW(learning_rate=initial_lr, weight_decay=1e-4)\n","\n","    # FIXED: Use SparseCategoricalCrossentropy for each output\n","    # This works with integer labels (no need for one-hot encoding)\n","    model.compile(\n","        optimizer=optimizer,\n","        loss={\n","            'age_output': losses.SparseCategoricalCrossentropy(),\n","            'gender_output': losses.SparseCategoricalCrossentropy(),\n","            'race_output': losses.SparseCategoricalCrossentropy()\n","        },\n","        loss_weights={\n","            'age_output': 1.0,\n","            'gender_output': 1.0,\n","            'race_output': 1.0\n","        },\n","        metrics={\n","            'age_output': ['sparse_categorical_accuracy'],\n","            'gender_output': ['sparse_categorical_accuracy'],\n","            'race_output': ['sparse_categorical_accuracy']\n","        }\n","    )\n","\n","    return model\n","\n","# # Custom loss function for multi-task learning\n","# class MultiTaskLoss(tf.keras.losses.Loss):\n","#     def __init__(self, age_weight=1.0, gender_weight=1.0, race_weight=1.0, name=\"multi_task_loss\"):\n","#         super().__init__(name=name)\n","#         self.age_weight = age_weight\n","#         self.gender_weight = gender_weight\n","#         self.race_weight = race_weight\n","#         # Use SparseCategoricalCrossentropy as the dataset provides integer labels\n","#         self.sparse_ce = tf.keras.losses.SparseCategoricalCrossentropy()\n","\n","#     def call(self, y_true, y_pred):\n","#         # y_true will be integer labels, y_pred will be one-hot encoded predictions\n","#         # SparseCategoricalCrossentropy expects integer labels and one-hot predictions\n","\n","#         age_loss = self.sparse_ce(y_true['age_output'], y_pred['age_output'])\n","#         gender_loss = self.sparse_ce(y_true['gender_output'], y_pred['gender_output'])\n","#         race_loss = self.sparse_ce(y_true['race_output'], y_pred['race_output'])\n","\n","#         total_loss = (self.age_weight * age_loss +\n","#                      self.gender_weight * gender_loss +\n","#                      self.race_weight * race_loss)\n","\n","#         return total_loss\n","\n","#     def build(self, input_shape):\n","#         # Properly initialize all layers\n","#         dummy_input = tf.keras.Input(shape=input_shape[1:])\n","#         self.call(dummy_input)\n","\n","# # Custom metrics\n","# class MultiTaskAccuracy(tf.keras.metrics.Metric):\n","#     def __init__(self, task_name, name=None, **kwargs):\n","#         if name is None:\n","#             name = f'{task_name}_accuracy'\n","#         super().__init__(name=name, **kwargs)\n","#         self.task_name = task_name\n","#         # Use SparseCategoricalAccuracy as the dataset provides integer labels\n","#         self.accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","\n","#     def update_state(self, y_true, y_pred, sample_weight=None):\n","#         # y_true will be integer labels, y_pred will be one-hot encoded predictions\n","#         # SparseCategoricalAccuracy expects integer labels and one-hot predictions\n","#         self.accuracy.update_state(y_true[self.task_name], y_pred[self.task_name], sample_weight)\n","\n","#     def result(self):\n","#         return self.accuracy.result()\n","\n","#     def reset_state(self):\n","#         self.accuracy.reset_state()"],"metadata":{"id":"1drJhus-PYHr","executionInfo":{"status":"ok","timestamp":1754078116166,"user_tz":-60,"elapsed":13,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","IMG_SIZE = 160\n","EPOCHS = 20\n","SAMPLE_SIZE = 5000  # Reduced sample size to avoid memory issues\n","\n","print(\"Creating training data processor...\")\n","train_processor = FairFaceDataProcessor(\n","    TRAIN_CSV_PATH,\n","    DATASET_PATH,\n","    img_size=IMG_SIZE,\n","    sample_size=SAMPLE_SIZE,\n","    is_validation=False\n",")\n","\n","print(\"\\nCreating validation data processor...\")\n","val_processor = FairFaceDataProcessor(\n","    VAL_CSV_PATH,\n","    DATASET_PATH,\n","    img_size=IMG_SIZE,\n","    sample_size=SAMPLE_SIZE//5 if SAMPLE_SIZE else None,\n","    is_validation=True\n",")\n","\n","# Copy encoders from training to validation processor\n","val_processor.age_encoder = train_processor.age_encoder\n","val_processor.gender_encoder = train_processor.gender_encoder\n","val_processor.race_encoder = train_processor.race_encoder\n","\n","# Re-encode validation labels with training encoders\n","val_processor.df['age_encoded'] = val_processor.age_encoder.transform(val_processor.df['age'])\n","val_processor.df['gender_encoded'] = val_processor.gender_encoder.transform(val_processor.df['gender'])\n","val_processor.df['race_encoded'] = val_processor.race_encoder.transform(val_processor.df['race'])\n","\n","print(\"\\nCreating datasets...\")\n","train_dataset = train_processor.create_dataset(\n","    batch_size=BATCH_SIZE,\n","    augment=True,\n","    shuffle=True\n",")\n","\n","val_dataset = val_processor.create_dataset(\n","    batch_size=BATCH_SIZE,\n","    augment=False,\n","    shuffle=False\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WTcl-yIykK6","executionInfo":{"status":"ok","timestamp":1754078116628,"user_tz":-60,"elapsed":459,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}},"outputId":"0ead33e4-7cc0-4bf8-d373-ca6cee238b0d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating training data processor...\n","Sampled training: 5000 samples\n","Classes - Age: 9, Gender: 2, Race: 7\n","Age groups: ['0-2', '10-19', '20-29', '3-9', '30-39', '40-49', '50-59', '60-69', 'more than 70']\n","Gender groups: ['Female', 'Male']\n","Race groups: ['Black', 'East Asian', 'Indian', 'Latino_Hispanic', 'Middle Eastern', 'Southeast Asian', 'White']\n","\n","Creating validation data processor...\n","Sampled validation: 1000 samples\n","Classes - Age: 9, Gender: 2, Race: 7\n","\n","Creating datasets...\n"]}]},{"cell_type":"code","source":["print(\"Building model...\")\n","model = create_and_compile_model(\n","    num_age_classes=train_processor.num_classes['age'],\n","    num_gender_classes=train_processor.num_classes['gender'],\n","    num_race_classes=train_processor.num_classes['race'],\n","    freeze_backbone=True  # Freeze FaceNet weights initially\n",")\n","\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":308},"id":"bv7OlybkARBz","executionInfo":{"status":"ok","timestamp":1754078119995,"user_tz":-60,"elapsed":3364,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}},"outputId":"bf2aa497-6bcd-4c06-9766-049443889fdf"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Building model...\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"face_net_multi_task\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"face_net_multi_task\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ inception_resnet_v1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m23,497,424\u001b[0m │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ age_head (\u001b[38;5;33mSequential\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gender_head (\u001b[38;5;33mSequential\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ race_head (\u001b[38;5;33mSequential\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ inception_resnet_v1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,497,424</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ age_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gender_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ race_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,497,424\u001b[0m (89.64 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,497,424</span> (89.64 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,497,424\u001b[0m (89.64 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,497,424</span> (89.64 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":["callbacks = [\n","    tf.keras.callbacks.ModelCheckpoint(\n","        '/content/best_fairface_facenet_model.h5',\n","        monitor='val_loss',\n","        save_best_only=True,\n","        save_weights_only=False,\n","        verbose=1\n","    ),\n","    tf.keras.callbacks.ReduceLROnPlateau(\n","        monitor='val_loss',\n","        factor=0.5,\n","        patience=5,\n","        min_lr=1e-7,\n","        verbose=1\n","    ),\n","    tf.keras.callbacks.EarlyStopping(\n","        monitor='val_loss',\n","        patience=10,\n","        restore_best_weights=True,\n","        verbose=1\n","    )\n","]\n","\n","# Recreate datasets for training (fresh iterators)\n","# train_dataset = train_gen.create_dataset(\n","#     train_gen.train_df,\n","#     batch_size=BATCH_SIZE,\n","#     augment=True,\n","#     shuffle=True\n","# )\n","\n","# val_dataset = val_gen.create_dataset(\n","#    val_gen.val_df,\n","#     batch_size=BATCH_SIZE,\n","#     augment=False,\n","#     shuffle=False\n","# )"],"metadata":{"id":"MWotdjMtbOOw","executionInfo":{"status":"ok","timestamp":1754078120011,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def verify_dataset_structure():\n","    print(\"=== Dataset Structure Verification ===\")\n","\n","    # Check CSV files\n","    train_csv = pd.read_csv(TRAIN_CSV_PATH)\n","    val_csv = pd.read_csv(VAL_CSV_PATH)\n","\n","    print(f\"Training CSV shape: {train_csv.shape}\")\n","    print(f\"Validation CSV shape: {val_csv.shape}\")\n","    print(f\"Training CSV columns: {list(train_csv.columns)}\")\n","\n","    # Check image directories\n","    train_images = os.listdir(TRAIN_IMG_DIR)\n","    val_images = os.listdir(VAL_IMG_DIR) if os.path.exists(VAL_IMG_DIR) else []\n","\n","    print(f\"Training images found: {len(train_images)}\")\n","    print(f\"Validation images found: {len(val_images)}\")\n","\n","    # Check if CSV files match image files\n","    print(\"\\n=== File Matching Check ===\")\n","\n","    # Sample a few files from CSV and check if they exist\n","    sample_files = train_csv['file'].head(10).tolist()\n","    missing_files = []\n","\n","    for file_name in sample_files:\n","        # full_path = os.path.join(TRAIN_IMG_DIR, file_name)\n","        full_path = os.path.join(DATASET_PATH, file_name)\n","        if not os.path.exists(full_path):\n","            missing_files.append(full_path)\n","        else:\n","            print(f\"✓ Found: {full_path}\")\n","\n","    if missing_files:\n","        print(f\"✗ Missing files: {missing_files}\")\n","    else:\n","        print(\"✓ All sampled files found!\")\n","\n","    # Check first few rows of CSV\n","    print(f\"\\nFirst few rows of training CSV:\")\n","    print(train_csv.head())\n","\n","    return len(missing_files) == 0\n","\n","# Run verification\n","dataset_ok = verify_dataset_structure()\n","\n","if dataset_ok:\n","    print(\"\\n✓ Dataset structure looks good! Proceeding with training...\")\n","else:\n","    print(\"\\n✗ Dataset structure issues found. Please check file paths.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ys2IgG9HiWZ","executionInfo":{"status":"ok","timestamp":1754078120407,"user_tz":-60,"elapsed":382,"user":{"displayName":"Ayobami Adeyemo","userId":"07870659355035613187"}},"outputId":"bca906e6-4e55-4be8-a513-8e08b5278abf"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Dataset Structure Verification ===\n","Training CSV shape: (86744, 5)\n","Validation CSV shape: (10954, 5)\n","Training CSV columns: ['file', 'age', 'gender', 'race', 'service_test']\n","Training images found: 26399\n","Validation images found: 0\n","\n","=== File Matching Check ===\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/1.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/2.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/3.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/4.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/5.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/6.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/7.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/8.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/9.jpg\n","✓ Found: /content/drive/MyDrive/datasets/FairFace/train/10.jpg\n","✓ All sampled files found!\n","\n","First few rows of training CSV:\n","          file    age  gender        race  service_test\n","0  train/1.jpg  50-59    Male  East Asian          True\n","1  train/2.jpg  30-39  Female      Indian         False\n","2  train/3.jpg    3-9  Female       Black         False\n","3  train/4.jpg  20-29  Female      Indian          True\n","4  train/5.jpg  20-29  Female      Indian          True\n","\n","✓ Dataset structure looks good! Proceeding with training...\n"]}]},{"cell_type":"code","source":["print(\"Starting training...\")\n","history = model.fit(\n","    train_dataset,\n","    epochs=10,\n","    validation_data=val_dataset,\n","    callbacks=callbacks,\n","    verbose=1\n",")\n","\n","print(\"Training completed!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19fY68tkbhW6","outputId":"eaed1089-2ed7-4d09-dfcc-949de4c67e83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training...\n","Epoch 1/10\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/67860.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/62903.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/63832.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/40144.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/73256.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/37858.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/66681.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/63704.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/48119.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/54224.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/66378.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/47082.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/38029.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/84888.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/57270.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/47215.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/72860.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/54738.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/64493.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/68529.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/52598.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/77743.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/5155.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/76895.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/59278.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/85534.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/46300.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/64065.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/492.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/51647.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/69276.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/36057.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/85777.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/37814.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/51166.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/77129.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/70853.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/9723.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/7252.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/50658.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/41941.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/48143.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/72160.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/38864.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/43235.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/59691.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/72237.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/68363.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/41879.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/72408.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/81168.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/54679.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/74294.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/63684.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/8828.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/76673.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/53325.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/72183.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/68356.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/5861.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/61253.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/41337.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/9556.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/80755.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/37916.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/3712.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/41603.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/55339.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/56086.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/8070.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/85194.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/37982.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/83382.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/82833.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/49622.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/50077.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/5780.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/61850.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/54933.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/49127.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/6831.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/41397.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/63318.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/36222.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/78467.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/76610.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/47168.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/62946.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/63862.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/60779.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/47470.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/83993.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/46387.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/65847.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/33802.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/62878.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/67747.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/73733.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/79408.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/33818.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/72188.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/52454.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/80018.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/74822.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/65530.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/35324.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/34341.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/62098.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/75954.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/81960.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/48104.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/35889.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/78945.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/55576.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/44477.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/75558.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/59402.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/48367.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/33935.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/86744.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/74740.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/7835.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/79977.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/63527.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/59726.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/62309.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/78883.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/45224.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/85252.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/7336.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/84494.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/65158.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/48458.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/9031.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/35472.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/78714.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/38610.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/47528.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/57822.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/83734.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/50636.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/37795.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/51733.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/36532.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/43758.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/85806.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/84171.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/380.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/64740.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/35190.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/78644.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/70437.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/69350.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/64503.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/49198.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/39504.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/55682.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/65687.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/7721.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/52251.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/41094.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/37246.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/40688.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/51986.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/65576.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/6449.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/82780.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/67377.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/36302.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/54376.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/5041.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/73018.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/55206.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/50366.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/68358.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/75488.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/72364.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/6599.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/74367.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/83645.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/68120.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/84574.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/71070.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/75166.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/46952.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/75227.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/42305.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/70222.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/63301.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/43141.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/76379.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/65359.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/6718.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/66515.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/80005.jpg\n","Warning: File not found: /content/drive/MyDrive/datasets/FairFace/train/83936.jpg\n"]}]},{"cell_type":"code","source":["# Plot training history\n","def plot_history(history):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","\n","    # Loss\n","    ax1.plot(history.history['loss'], label='Train')\n","    ax1.plot(history.history['val_loss'], label='Validation')\n","    ax1.set_title('Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.legend()\n","\n","    # Accuracy (Age)\n","    ax2.plot(history.history['age_output_accuracy'], label='Age Train')\n","    ax2.plot(history.history['val_age_output_accuracy'], label='Age Val')\n","    ax2.plot(history.history['gender_output_accuracy'], label='Gender Train')\n","    ax2.plot(history.history['val_gender_output_accuracy'], label='Gender Val')\n","    ax2.plot(history.history['race_output_accuracy'], label='Race Train')\n","    ax2.plot(history.history['val_race_output_accuracy'], label='Race Val')\n","    ax2.set_title('Task Accuracy')\n","    ax2.set_xlabel('Epoch')\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_history(history)\n","\n","# Load best model\n","model = models.load_model('best_model.h5')\n","\n","# Evaluate\n","results = model.evaluate(val_gen)\n","print(\"\\nEvaluation Results:\")\n","print(f\"Age Accuracy: {results[4]:.4f}\")\n","print(f\"Gender Accuracy: {results[6]:.4f}\")\n","print(f\"Race Accuracy: {results[8]:.4f}\")\n"],"metadata":{"id":"wfeTgSyaEQxk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_sample(model, img_path, img_size=(160, 160)):\n","    # Load and preprocess image\n","    img = tf.io.read_file(img_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, img_size)\n","    img = tf.subtract(img, 0.5)\n","    img = tf.multiply(img, 2.0)\n","    img = tf.expand_dims(img, axis=0)  # Add batch dim\n","\n","    # Predict\n","    preds = model.predict(img)\n","    age_pred = np.argmax(preds[0][0])\n","    gender_pred = np.argmax(preds[1][0])\n","    race_pred = np.argmax(preds[2][0])\n","\n","    # Decode labels\n","    age_label = train_gen.age_encoder.inverse_transform([age_pred])[0]\n","    gender_label = train_gen.gender_encoder.inverse_transform([gender_pred])[0]\n","    race_label = train_gen.race_encoder.inverse_transform([race_pred])[0]\n","\n","    # Display\n","    plt.imshow(tf.squeeze(img) * 0.5 + 0.5)  # Undo normalization\n","    plt.title(f\"Age: {age_label}\\nGender: {gender_label}\\nRace: {race_label}\")\n","    plt.axis('off')\n","    plt.show()\n","\n","    return age_label, gender_label, race_label\n","\n","# Test on a sample image\n","sample_img = os.path.join(VAL_IMG_DIR, os.listdir(VAL_IMG_DIR)[0])\n","predict_sample(model, sample_img)\n"],"metadata":{"id":"MHB5nbuNEZWU"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","mount_file_id":"1QWnY7-M1agv-s49cd3xZqMZqsRkQlEls","authorship_tag":"ABX9TyNewVvIoBLoLgeAMzBqFHqS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}